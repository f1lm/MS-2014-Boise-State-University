<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!-- saved from url=(0053)http://research.neustar.biz/tag/streaming-algorithms/ -->
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en" class=""><!--
	generated 279 seconds ago
	generated in 0.412 seconds
	served from batcache in 0.004 seconds
	expires in 21 seconds
--><head profile="http://gmpg.org/xfn/11"><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

<title>Streaming Algorithms – Research</title>
		<script src="./Streaming Algorithms – Research_files/remote-login.php" type="text/javascript"></script><style type="text/css"></style>
		<script type="text/javascript">
		/* <![CDATA[ */
			if ( 'function' === typeof WPRemoteLogin ) {
				document.cookie = "wordpress_test_cookie=test; path=/";
				if ( document.cookie.match( /(;|^)\s*wordpress_test_cookie\=/ ) ) {
					WPRemoteLogin();
				}
			}
		/* ]]> */
		</script>
		<link rel="alternate" type="application/rss+xml" title="Research » Feed" href="http://research.neustar.biz/feed/">
<link rel="alternate" type="application/rss+xml" title="Research » Comments Feed" href="http://research.neustar.biz/comments/feed/">
<link rel="alternate" type="application/rss+xml" title="Research » Streaming Algorithms Tag Feed" href="http://research.neustar.biz/tag/streaming-algorithms/feed/">
<script type="text/javascript">
/* <![CDATA[ */
function addLoadEvent(func){var oldonload=window.onload;if(typeof window.onload!='function'){window.onload=func;}else{window.onload=function(){oldonload();func();}}}
/* ]]> */
</script>
<link rel="stylesheet" id="all-css-0" href="./Streaming Algorithms – Research_files/saved_resource" type="text/css" media="all">
<link rel="stylesheet" id="googlefont-droid-serif-css" href="./Streaming Algorithms – Research_files/css" type="text/css" media="all">
<link rel="stylesheet" id="googlefont-oswald-css" href="./Streaming Algorithms – Research_files/css(1)" type="text/css" media="all">
<link rel="stylesheet" id="all-css-4" href="./Streaming Algorithms – Research_files/saved_resource(1)" type="text/css" media="all">
<script type="text/javascript">
/* <![CDATA[ */
var LoggedOutFollow = {"invalid_email":"Your subscription did not succeed, please try again with a valid email address."};
/* ]]> */
</script>
<script type="text/javascript" src="./Streaming Algorithms – Research_files/saved_resource(2)"></script>
<link rel="EditURI" type="application/rsd+xml" title="RSD" href="http://agkn.wordpress.com/xmlrpc.php?rsd">
<link rel="wlwmanifest" type="application/wlwmanifest+xml" href="http://s1.wp.com/wp-includes/wlwmanifest.xml"> 
<meta name="generator" content="WordPress.com">
<link rel="shortcut icon" type="image/x-icon" href="http://1.gravatar.com/blavatar/3c18461d25b6d04974508a029188a417?s=16" sizes="16x16">
<link rel="icon" type="image/x-icon" href="http://1.gravatar.com/blavatar/3c18461d25b6d04974508a029188a417?s=16" sizes="16x16">
<link rel="apple-touch-icon-precomposed" href="http://1.gravatar.com/blavatar/f7c9c0215768938a158a2d13f6937ade?s=114">
<link rel="openid.server" href="http://agkn.wordpress.com/?openidserver=1">
<link rel="openid.delegate" href="http://agkn.wordpress.com/">
<link rel="search" type="application/opensearchdescription+xml" href="http://research.neustar.biz/osd.xml" title="Research">
<link rel="search" type="application/opensearchdescription+xml" href="http://wordpress.com/opensearch.xml" title="WordPress.com">
<link rel="pingback" href="http://research.neustar.biz/xmlrpc.php">
<style type="text/css">#header { background: url(http://s0.wp.com/wp-content/themes/premium/minimum/images/header.png) no-repeat !important; }</style>
<style type="text/css">body { background-image: none; }</style><meta name="application-name" content="Research"><meta name="msapplication-window" content="width=device-width;height=device-height"><meta name="msapplication-task" content="name=Subscribe;action-uri=http://research.neustar.biz/feed/;icon-uri=http://1.gravatar.com/blavatar/3c18461d25b6d04974508a029188a417?s=16"><meta name="msapplication-task" content="name=Sign up for a free blog;action-uri=http://wordpress.com/signup/;icon-uri=http://s2.wp.com/i/favicon.ico"><meta name="msapplication-task" content="name=WordPress.com Support;action-uri=http://support.wordpress.com/;icon-uri=http://s2.wp.com/i/favicon.ico"><meta name="msapplication-task" content="name=WordPress.com Forums;action-uri=http://forums.wordpress.com/;icon-uri=http://s2.wp.com/i/favicon.ico"><style type="text/css" id="custom-background-css">
body.custom-background { background-color: #ffffff; }
</style>
<link rel="stylesheet" type="text/css" href="./Streaming Algorithms – Research_files/shCore.css"><link rel="stylesheet" type="text/css" href="./Streaming Algorithms – Research_files/shThemeDefault.css"><style type="text/css" id="syntaxhighlighteranchor"></style>
<style type="text/css" id="custom-colors-css">
body { background-color: #ffffff;}
h1, h2, h3, h4, h5, h6, h2 a, h2 a:visited, h4 a, h4 a:hover, h4 a:visited { color: #3B3F3D;}
a, a:visited { color: #9F2064;}
#header ul.nav li a:hover, #header ul.nav li a:active, #header ul.nav .current_page_item a, #header ul.nav .current-cat a, #header ul.nav .current-menu-item a, #header ul.menu li a:hover, #header ul.menu li a:active, #header ul.menu .current_page_item a, #header ul.menu .current-cat a, #header ul.menu .current-menu-item a { color: #9F2064;}
#header ul.nav li li a:hover, #header ul.nav li li a:active, #header ul.menu li li a:hover, #header ul.menu li li a:active, .widget_archive select, .s, .enews #subbox, #footer a:hover { color: #9F2064;}
#nav li a:hover, #nav li a:active, #nav .current_page_item a, #nav .current-cat a, #nav .current-menu-item a, #subnav li li a:hover, #subnav li li a:active, h2 a:hover, #cat { color: #9F2064;}
#nav li li a:hover, #nav li li a:active, #nav li.right a:hover, #subnav li a:hover, #subnav li a:active, #subnav .current_page_item a, #subnav .current-cat a, #subnav .current-menu-item a { color: #9F2064;}
div.gform_footer input.button:hover, .enews #subbutton:hover, .searchsubmit:hover, .widget_blog_subscription input:hover, #submit:hover { background-color: #9F2064;}
div.gform_footer input.button:hover, .enews #subbutton:hover, .searchsubmit:hover, .widget_blog_subscription input:hover, #submit:hover { border-color: #9F2064;}
body { border-top-color: #9F2064;}
</style>
		<link rel="stylesheet" id="custom-css-css" type="text/css" href="./Streaming Algorithms – Research_files/saved_resource(3)">
		<link rel="stylesheet" type="text/css" href="chrome-extension://cgndfbhngibokieehnjhbjkkhbfmhojo/css/validation.css"><style type="text/css">.fancybox-margin{margin-right:0px;}</style></head>
<body class="archive tag tag-streaming-algorithms tag-14138358 custom-background mp6 typekit-enabled custom-header header-image header-full-width full-width-content highlander-enabled highlander-light custom-colors" data-gclp-initialized="true" data-gistbox-initialized="true"><div id="wrap"><div id="header"><div class="wrap"><div id="title-area"><p id="title"><a href="http://research.neustar.biz/" title="Research">Research</a></p></div></div></div><div id="inner"><div id="content-sidebar-wrap"><div id="content" class="hfeed"><div class="post-6281 post type-post status-publish format-standard hentry category-data-science category-general tag-agile-analytics tag-databases tag-hll tag-hyperloglog tag-java tag-pg tag-postgresql tag-probabilistic-sketching tag-sketching tag-streaming tag-streaming-algorithms entry"><h2 class="entry-title"><a href="http://research.neustar.biz/2014/09/23/hll-talk-at-sfpug/" title="HLL talk at SFPUG" rel="bookmark">HLL talk at&nbsp;SFPUG</a></h2> 
<div class="post-info"><span class="date published time" title="2014-09-23T23:46:16+00:00">September 23, 2014</span>  by <span class="author vcard"><span class="fn"><a href="http://research.neustar.biz/author/timonk/" title="timonk" rel="author">timonk</a></span></span> <span class="post-comments"><a href="http://research.neustar.biz/2014/09/23/hll-talk-at-sfpug/#comments">1 Comment</a></span> </div><div class="entry-content"><p>I had the pleasure of speaking at the <a href="http://www.meetup.com/postgresql-1/" target="_blank">SF PostgreSQL User Group’s meetup</a> tonight about sketching, the history of HLL, and our <a href="http://research.neustar.biz/tag/streaming-algorithms/github.com/aggregateknowledge/postgresql-hll" target="_blank">implementation of HLL as a PG extension</a>. My slides are embedded below and you can get a PDF copy <a href="https://agkn.files.wordpress.com/2014/09/hll-sfpug-2014-09-23.pdf" target="_blank">here</a>. Be sure to click the gear below to show speaker’s notes for context!</p>
<iframe src="./Streaming Algorithms – Research_files/embed.html" frameborder="0" width="960" height="569" marginheight="0" marginwidth="0"></iframe>
<p>If video is made available, I’ll post an update with a link!</p>
</div><div class="post-meta"><span class="categories">Filed Under: <a href="http://research.neustar.biz/category/data-science/" rel="category tag">Data Science</a>, <a href="http://research.neustar.biz/category/general/" rel="category tag">General</a></span> <span class="tags">Tagged With: <a href="http://research.neustar.biz/tag/agile-analytics/" rel="tag">Agile Analytics</a>, <a href="http://research.neustar.biz/tag/databases/" rel="tag">Databases</a>, <a href="http://research.neustar.biz/tag/hll/" rel="tag">HLL</a>, <a href="http://research.neustar.biz/tag/hyperloglog/" rel="tag">HyperLogLog</a>, <a href="http://research.neustar.biz/tag/java/" rel="tag">Java</a>, <a href="http://research.neustar.biz/tag/pg/" rel="tag">PG</a>, <a href="http://research.neustar.biz/tag/postgresql/" rel="tag">PostgreSQL</a>, <a href="http://research.neustar.biz/tag/probabilistic-sketching/" rel="tag">Probabilistic Sketching</a>, <a href="http://research.neustar.biz/tag/sketching/" rel="tag">Sketching</a>, <a href="http://research.neustar.biz/tag/streaming/" rel="tag">Streaming</a>, <a href="./Streaming Algorithms – Research_files/Streaming Algorithms – Research.html" rel="tag">Streaming Algorithms</a></span></div></div><div class="post-5596 post type-post status-publish format-standard hentry category-data-science category-general tag-hash-function tag-hashing tag-probabilistic-sketching tag-sketching tag-streaming tag-streaming-algorithms entry"><h2 class="entry-title"><a href="http://research.neustar.biz/2014/07/22/hitting-the-books-eads-summer-school-on-hashing/" title="Hitting the Books: EADS Summer School on Hashing" rel="bookmark">Hitting the Books: EADS Summer School on&nbsp;Hashing</a></h2> 
<div class="post-info"><span class="date published time" title="2014-07-22T13:48:38+00:00">July 22, 2014</span>  by <span class="author vcard"><span class="fn"><a href="http://research.neustar.biz/author/timonk/" title="timonk" rel="author">timonk</a></span></span> <span class="post-comments"><a href="http://research.neustar.biz/2014/07/22/hitting-the-books-eads-summer-school-on-hashing/#comments">5 Comments</a></span> </div><div class="entry-content"><p>Rob, Matt, and I just wrapped up our trip to Copenhagen for the <a href="http://www.diku.dk/summer-school-2014/" target="_blank">EADS Summer School on Hashing at the University of Copenhagen</a> and it was a blast! The lineup of speakers was, simply put, unbeatable: <a href="http://www.itu.dk/people/pagh/" target="_blank">Rasmus Pagh</a>, <a href="http://www2.warwick.ac.uk/fac/sci/dcs/people/graham_cormode/" target="_blank">Graham Cormode</a>, <a href="http://www.eecs.harvard.edu/~michaelm/" target="_blank">Michael Mitzenmacher</a>, <a href="http://www.diku.dk/~mthorup/" target="_blank">Mikkel Thorup</a>, <a href="http://research.microsoft.com/en-us/people/andoni/" target="_blank">Alex Andoni</a>, <a href="http://www.cs.tau.ac.il/~haimk/" target="_blank">Haim Kaplan</a>, <a href="http://hunch.net/~jl/" target="_blank">John Langford</a>, and <a href="http://www.cs.utah.edu/~suresh/web/" target="_blank">Suresh&nbsp;Venkatasubramanian</a>. There’s a good chance that any paper you’ve read on hashing, sketching, or streaming has one of them as a co-author or is heavily influenced by their work. The format was three hour-and-a-half lectures for four days, with exercises presented at the end of each lecture. (Slides can be found <a href="http://www.diku.dk/summer-school-2014/course-material/" target="_blank">here</a>. <del>They might also post videos.</del>&nbsp;<strong>UPDATE:&nbsp;</strong><a href="http://www.youtube.com/playlist?list=PLT_GI2oINs-CRuwMGDa5_frB7kC7blf__" target="_blank">They’ve posted videos!</a>)</p>
<p>Despite the depth of the material, almost all of it was approachable with some experience in undergraduate math and computer science. We would strongly recommend both of Michael Mitzenmacher’s talks (<a href="http://www.diku.dk/summer-school-2014/course-material/michael-mitzenmacher/DenmarkSummerSchool.pdf" target="_blank">1</a>, <a href="http://www.diku.dk/summer-school-2014/course-material/michael-mitzenmacher/DenmarkSummerSchool2.pdf" target="_blank">2</a>) for an excellent overview of Bloom Filters and Cuckoo hashing that are, in my opinion, significantly better and more in depth than any other out there. Specifically, the Bloom Filter talk presents very elegantly the continuum of Bloom Filter to Counting Bloom Filter to Count-Min Sketch (with “conservative update”) to the Stragglers Problem and Invertible Bloom Filters to, finally, extremely recent work called <a href="http://www.itu.dk/people/pagh/papers/oddsketch.pdf" target="_blank">Odd Sketches</a>.</p>
<p>Similarly, Mikkel Thorup’s two talks on hashing (<a href="http://www.diku.dk/summer-school-2014/course-material/mikkel-thorup/hash.pdf_copy" target="_blank">1</a>, <a href="http://www.diku.dk/summer-school-2014/course-material/mikkel-thorup/tabulation-summer-school14.pdf" target="_blank">2</a>) do a very thorough job of examining the hows and whys of integer hashing, all the way from the simplest multiply-mod-prime schemes all the way to modern work on tabulation hashing. And if you haven’t heard of tabulation hashing, and specifically twisted tabulation hashing, get on that because (1) it’s amazing that it doesn’t produce trash given how simple it is, (2) it’s unbelievably fast, and (3) it has been&nbsp;<em>proven</em> to provide the guarantees required for almost all&nbsp;of the interesting topics we’ve discussed on the blog in the past: Bloom Filters, Count-Min sketch, HyperLogLog, chaining/linear-probing/cuckoo hash tables, and so on. We really appreciated how much attention Mikkel devoted to practicality of implementation and to empirical performance when discussing hashing algorithms. It warms our heart to hear a leading academic in this field tout the number of&nbsp;nanoseconds it takes to hash an item as vocally as the elegance of the proof behind it!</p>
<p>We love this “Summer School” format because it delivers&nbsp;the accumulated didactic insight of the field’s top researchers and educators to both old techniques and brand new ones. (And we hope by now that everyone reading our blog appreciates how obsessed we are with teaching and clarifying interesting algorithms and data structures!) Usually most of this insight (into origins, creative process, stumbling blocks, intermediate results, inspiration, etc.) only comes out in conversation or lectures, and&nbsp;even worse is withheld&nbsp;or elided at&nbsp;publishing time for the sake of “clarity” or “elegance”, which is a baffling rationale given how useful these “notes in the margin” have been to us. The longer format of the lectures really allowed for useful&nbsp;“digressions” into the history or inspiration for topics or proofs, which is a huge contrast to the 10-minute presentations given at a conference like SODA. (Yes, obviously the objective of SODA is to show a much greater breadth of work, but it really makes it hard to explain or digest the context of new work.)</p>
<p>In much the same way, the length of the program really gave us the opportunity to have great conversations with the speakers and attendees between sessions and over dinner. We can’t emphasize this enough: if your ambition to is implement and understand cutting edge algorithms and data structures then the best bang for your buck is to get out there and meet the researchers in person. We’re incredibly lucky to call most of the speakers our friends and to regularly trade notes and get pointers to new research. They have helped us time and again when we’ve been baffled by inconsistent terminology or had a hunch that two pieces of research&nbsp;were “basically saying the&nbsp;same thing”. Unsurprisingly, they are also the best group of people to talk to when it comes to understanding how to foster a culture of successful research. For instance, Mikkel has a great article on&nbsp;how to systematically encourage and reward research article that <a href="http://dl.acm.org/citation.cfm?id=2428569" target="_blank">appears in the March 2013 issue of CACM</a>&nbsp;(pay-wall’d). Also worthwhile is his <a href="http://bertrandmeyer.com/2011/12/27/guest-column-funding-great-research/" target="_blank">guest post</a> on Bertrand Meyer’s blog.</p>
<p>If Mikkel decides to host another one of these, we cannot recommend attending enough. (Did we mention it&nbsp;was free?!) Thanks again Mikkel, Rasmus, Graham, Alex, Michael, Haim, and John for organizing such a great program and lecturing so eloquently!</p>
</div><div class="post-meta"><span class="categories">Filed Under: <a href="http://research.neustar.biz/category/data-science/" rel="category tag">Data Science</a>, <a href="http://research.neustar.biz/category/general/" rel="category tag">General</a></span> <span class="tags">Tagged With: <a href="http://research.neustar.biz/tag/hash-function/" rel="tag">Hash Function</a>, <a href="http://research.neustar.biz/tag/hashing/" rel="tag">Hashing</a>, <a href="http://research.neustar.biz/tag/probabilistic-sketching/" rel="tag">Probabilistic Sketching</a>, <a href="http://research.neustar.biz/tag/sketching/" rel="tag">Sketching</a>, <a href="http://research.neustar.biz/tag/streaming/" rel="tag">Streaming</a>, <a href="./Streaming Algorithms – Research_files/Streaming Algorithms – Research.html" rel="tag">Streaming Algorithms</a></span></div></div><div class="post-4292 post type-post status-publish format-standard hentry category-data-science category-sketch-of-the-day tag-big-data tag-data-science tag-probabilistic-sketching tag-real-time-streaming tag-sketching tag-streaming-algorithms entry"><h2 class="entry-title"><a href="http://research.neustar.biz/2013/09/16/sketch-of-the-day-frugal-streaming/" title="Sketch of the Day: Frugal Streaming" rel="bookmark">Sketch of the Day: Frugal&nbsp;Streaming</a></h2> 
<div class="post-info"><span class="date published time" title="2013-09-16T11:33:40+00:00">September 16, 2013</span>  by <span class="author vcard"><span class="fn"><a href="http://research.neustar.biz/author/wwkae/" title="mattcurcio" rel="author">mattcurcio</a></span></span> <span class="post-comments"><a href="http://research.neustar.biz/2013/09/16/sketch-of-the-day-frugal-streaming/#comments">14 Comments</a></span> </div><div class="entry-content"><p>We are always worried about the size of our <a href="http://blog.aggregateknowledge.com/tag/sketching/">sketches</a>. At AK we like to count stuff, and if you can count stuff with smaller sketches then you can count more stuff! We constantly have conversations about how we might be able to make our sketches, and subsequently our datastores, smaller. During our <a href="http://blog.aggregateknowledge.com/2013/06/25/data-science-summit-update/">science summit</a>, <a href="http://www.cs.rutgers.edu/~muthu/">Muthu</a> pointed us at some of the new work in <a href="http://link.springer.com/content/pdf/10.1007%2F978-3-642-40273-9_7.pdf">Frugal Streaming</a>. The concept of Frugal Streaming is to process your data as it comes, <em>O(N)</em>, but severely limit the amount of memory you are using for your sketch, and by “severely” they mean using perhaps one or two pieces of information. Needless to say, we were interested!</p>
<h3>History</h3>
<p>The concept of Frugal Streaming reminds me of an algorithm for finding the dominant item in a stream, <a href="http://www.cs.utexas.edu/~moore/best-ideas/mjrty/">MJRTY</a> written by Boyer and Moore in 1980. (This paper has a very interesting <a href="http://blogs.law.harvard.edu/pamphlet/2011/09/23/tales-of-peer-review-episode-1-boyer-and-moores-mjrty-algorithm/">history</a>). The MJRTY algorithm sets out to solve the problem of finding the majority element in a stream (an element comprising more than 50% of the stream). Moore proposed to solve this by using only 2 pieces of information and a single scan of the data.</p>
<p>Imagine you have a stream of names (“matt”, “timon”, “matt”, “matt”, “rob”, “ben”, …) and you wanted to know if any name appeared in more than half the stream. Boyer and Moore proposed the following:</p>
<div><div id="highlighter_763668" class="syntaxhighlighter  python"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div><div class="line number3 index2 alt2">3</div><div class="line number4 index3 alt1">4</div><div class="line number5 index4 alt2">5</div><div class="line number6 index5 alt1">6</div><div class="line number7 index6 alt2">7</div><div class="line number8 index7 alt1">8</div><div class="line number9 index8 alt2">9</div><div class="line number10 index9 alt1">10</div><div class="line number11 index10 alt2">11</div><div class="line number12 index11 alt1">12</div><div class="line number13 index12 alt2">13</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="python plain">count </code><code class="python keyword">=</code> <code class="python value">0</code></div><div class="line number2 index1 alt1"><code class="python plain">majority </code><code class="python keyword">=</code> <code class="python plain">""</code></div><div class="line number3 index2 alt2">&nbsp;</div><div class="line number4 index3 alt1"><code class="python keyword">for</code> <code class="python plain">val </code><code class="python keyword">in</code> <code class="python plain">stream:</code></div><div class="line number5 index4 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python keyword">if</code> <code class="python plain">count </code><code class="python keyword">=</code><code class="python keyword">=</code> <code class="python value">0</code><code class="python plain">:</code></div><div class="line number6 index5 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">majority </code><code class="python keyword">=</code> <code class="python plain">val</code></div><div class="line number7 index6 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">count </code><code class="python keyword">=</code> <code class="python value">1</code></div><div class="line number8 index7 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python keyword">elif</code> <code class="python plain">val </code><code class="python keyword">=</code><code class="python keyword">=</code> <code class="python plain">majority:</code></div><div class="line number9 index8 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">count </code><code class="python keyword">+</code><code class="python keyword">=</code> <code class="python value">1</code></div><div class="line number10 index9 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python keyword">else</code><code class="python plain">:</code></div><div class="line number11 index10 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">count </code><code class="python keyword">-</code><code class="python keyword">=</code> <code class="python value">1</code></div><div class="line number12 index11 alt1">&nbsp;</div><div class="line number13 index12 alt2"><code class="python functions">print</code> <code class="python plain">majority </code><code class="python keyword">if</code> <code class="python plain">count &gt; </code><code class="python value">0</code> <code class="python keyword">else</code> <code class="python string">"no majority!"</code></div></div></td></tr></tbody></table></div></div>
<p>If you’re anything like me you will go through a few phases: “That can’t work!”, “Wait, that works?!”, “Nah, this data will break that”, “Holy sh*t that works!!”. If you think about it for a minute you realize that it HAS to work. If any element in the stream comprises more than half the stream values there is no way to get to the end and have a counter of zero. To convince yourself suppose the majority element only comprises the first half + 1 of your N-length stream. The counter would count up to <img src="./Streaming Algorithms – Research_files/latex.php" alt="N/2+1" title="N/2+1" class="latex"> and then start decrementing until all N values have been seen, which would leave the counter at <img src="./Streaming Algorithms – Research_files/latex(1).php" alt="2 = (N/2+1) - (N/2-1) " title="2 = (N/2+1) - (N/2-1) " class="latex">*. This will hold regardless of the ordering of the elements in the stream. A simple <a href="http://www.cs.utexas.edu/~moore/best-ideas/mjrty/example.html">simulation</a> is provided by the authors.   Philippe Flajolet apparently “liked this algorithm very much and called it the ‘gang war’, because in his mind, every element is a gang member, and members of opposite gangs are paired in a standoff, and shoot each other. The gang members remaining are the more numerous”**.</p>
<p>The astute among you will have noticed that this algorithm only works if there is, in fact, a majority element. If there is not then it will fail. A stream such as {“matt”,”matt”,”timon”,”timon”,”rob”} would result in the algorithm returning “rob”. In practice you need ways of ensuring that your stream does indeed have a majority element or have a guarantee ahead of time.</p>
<p>* Note, that formula is for an even length stream. For a stream of odd length the counter will indeed be at 1. Proof is left to the reader.</p>
<p>** Thanks to Jeremie Lumbroso for his insightful feedback on the history of MJRTY and his memory of Philippe’s explanation.</p>
<h3>One “bit” – Frugal-1U</h3>
<p>In their <a href="http://link.springer.com/content/pdf/10.1007%2F978-3-642-40273-9_7.pdf">Frugal Streaming paper</a>, Qiang and Muthu decided to see if they could find a frugal solution to the streaming quantile problem. The streaming quantiles problem is one I enjoy quite a bit and I have used it as an interview question for potential candidates for some time. Simply stated it is: “How would you find the quantiles of a stream of numbers in O(N) with limited memory?” There are a few different approaches to solve this problem, with the most widely known probably being <a href="http://blog.aggregateknowledge.com/tag/count-min-sketch/">Count-Min Sketch</a>. However, with Count-Min you need to keep your keys around in order to query the sketch. There are <a href="http://www.cs.ucsb.edu/~suri/psdir/ency.pdf">other approaches</a> to this question as well.</p>
<p>Instead of focusing on quantiles generally, Qiang and Muthu’s first solution is a frugal way to find the median of a stream. As with MJRTY above, I’ll just write it down and see how you react:</p>
<div><div id="highlighter_560335" class="syntaxhighlighter  python"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div><div class="line number3 index2 alt2">3</div><div class="line number4 index3 alt1">4</div><div class="line number5 index4 alt2">5</div><div class="line number6 index5 alt1">6</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="python plain">median_est </code><code class="python keyword">=</code> <code class="python value">0</code></div><div class="line number2 index1 alt1"><code class="python keyword">for</code> <code class="python plain">val </code><code class="python keyword">in</code> <code class="python plain">stream:</code></div><div class="line number3 index2 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python keyword">if</code> <code class="python plain">val &gt; median_est:</code></div><div class="line number4 index3 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">median_est </code><code class="python keyword">+</code><code class="python keyword">=</code> <code class="python value">1</code></div><div class="line number5 index4 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python keyword">elif</code> <code class="python plain">val &lt; median_est:</code></div><div class="line number6 index5 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">median_est </code><code class="python keyword">-</code><code class="python keyword">=</code> <code class="python value">1</code></div></div></td></tr></tbody></table></div></div>
<p>Granted, the above is just for the median, where the stream is much longer than the value of the median, but it is so simple that I don’t think I would have ever considered this approach to the problem.  The extension to quantiles is equally as shocking. If you are trying to find the 75th percentile of the data stream you do the same as above but increment up randomly 75% of the time and decrement down randomly 25% of the time:</p>
<div><div id="highlighter_182444" class="syntaxhighlighter  python"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div><div class="line number3 index2 alt2">3</div><div class="line number4 index3 alt1">4</div><div class="line number5 index4 alt2">5</div><div class="line number6 index5 alt1">6</div><div class="line number7 index6 alt2">7</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="python plain">quantile_75 </code><code class="python keyword">=</code> <code class="python value">0</code></div><div class="line number2 index1 alt1"><code class="python keyword">for</code> <code class="python plain">val </code><code class="python keyword">in</code> <code class="python plain">stream:</code></div><div class="line number3 index2 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">r </code><code class="python keyword">=</code> <code class="python plain">random()</code></div><div class="line number4 index3 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python keyword">if</code> <code class="python plain">val &gt; quantile_75 </code><code class="python keyword">and</code> <code class="python plain">r &gt; </code><code class="python value">1</code> <code class="python keyword">-</code> <code class="python value">0.75</code><code class="python plain">:</code></div><div class="line number5 index4 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">quantile_75 </code><code class="python keyword">+</code><code class="python keyword">=</code> <code class="python value">1</code></div><div class="line number6 index5 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python keyword">elif</code> <code class="python plain">val &lt; quantile_75 </code><code class="python keyword">and</code> <code class="python plain">r &gt; </code><code class="python value">0.75</code><code class="python plain">:</code></div><div class="line number7 index6 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">quantile_75 </code><code class="python keyword">-</code><code class="python keyword">=</code> <code class="python value">1</code></div></div></td></tr></tbody></table></div></div>
<p>As the paper states:</p>
<blockquote><p>The trick to generalize median estimation to any <img src="./Streaming Algorithms – Research_files/latex(2).php" alt="\frac{h}{k}" title="\frac{h}{k}" class="latex"> -quantile estimation is that not every stream item seen will cause an update. If the current stream item is larger than estimation, an increment update will be triggered only with probability <img src="./Streaming Algorithms – Research_files/latex(2).php" alt="\frac{h}{k}" title="\frac{h}{k}" class="latex">. The rationale behind it is that if we are estimating <img src="./Streaming Algorithms – Research_files/latex(2).php" alt="\frac{h}{k}" title="\frac{h}{k}" class="latex"> -quantile, and if the current estimate is at stream’s true <img src="./Streaming Algorithms – Research_files/latex(2).php" alt="\frac{h}{k}" title="\frac{h}{k}" class="latex"> -quantile, we will expect to see stream items larger than the current estimate with probability <img src="./Streaming Algorithms – Research_files/latex(3).php" alt="1-\frac{h}{k}" title="1-\frac{h}{k}" class="latex"> .</p></blockquote>
<h3>Finding Quantiles With Two “bits”- Frugal-2U</h3>
<p>There are a few obvious drawbacks to the above algorithm. Since we are only incrementing by 1 each time, the time to converge is linear and our initial guess of zero could be very bad. Secondly, and by design, the algorithm has no memory, can fluctuate wildly and, as they show in the paper, the estimates can drift very far away. (Note: while it is extremely unlikely that the estimates will drift far from the correct values the paper has some very loose bounds on how bad it can drift. See Lemma 3 in the paper.) They suggest a few improvements over Frugal-1U where you essentially include a varying step (instead of just incrementing by 1 every time) and 1 “bit” so you know which way you incremented in the last update. The intuition here is that if you have been consistently incrementing up or down for the last few elements of a stream then you are probably “far” away from the quantile in question. If this is the case we can speed up convergence time by incrementing a larger amount. The Frugal-2U algorithm:</p>
<div><div id="highlighter_774228" class="syntaxhighlighter  python"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div><div class="line number3 index2 alt2">3</div><div class="line number4 index3 alt1">4</div><div class="line number5 index4 alt2">5</div><div class="line number6 index5 alt1">6</div><div class="line number7 index6 alt2">7</div><div class="line number8 index7 alt1">8</div><div class="line number9 index8 alt2">9</div><div class="line number10 index9 alt1">10</div><div class="line number11 index10 alt2">11</div><div class="line number12 index11 alt1">12</div><div class="line number13 index12 alt2">13</div><div class="line number14 index13 alt1">14</div><div class="line number15 index14 alt2">15</div><div class="line number16 index15 alt1">16</div><div class="line number17 index16 alt2">17</div><div class="line number18 index17 alt1">18</div><div class="line number19 index18 alt2">19</div><div class="line number20 index19 alt1">20</div><div class="line number21 index20 alt2">21</div><div class="line number22 index21 alt1">22</div><div class="line number23 index22 alt2">23</div><div class="line number24 index23 alt1">24</div><div class="line number25 index24 alt2">25</div><div class="line number26 index25 alt1">26</div><div class="line number27 index26 alt2">27</div><div class="line number28 index27 alt1">28</div><div class="line number29 index28 alt2">29</div><div class="line number30 index29 alt1">30</div><div class="line number31 index30 alt2">31</div><div class="line number32 index31 alt1">32</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="python keyword">def</code> <code class="python plain">frugal_2u(stream, m </code><code class="python keyword">=</code> <code class="python value">0</code><code class="python plain">, q </code><code class="python keyword">=</code> <code class="python value">0.5</code><code class="python plain">, f </code><code class="python keyword">=</code> <code class="python plain">constantly_one):</code></div><div class="line number2 index1 alt1"><code class="python spaces">&nbsp;&nbsp;</code><code class="python plain">step, sign </code><code class="python keyword">=</code> <code class="python value">1</code><code class="python plain">, </code><code class="python value">1</code></div><div class="line number3 index2 alt2">&nbsp;</div><div class="line number4 index3 alt1"><code class="python keyword">for</code> <code class="python plain">item </code><code class="python keyword">in</code> <code class="python plain">stream:</code></div><div class="line number5 index4 alt2"><code class="python spaces">&nbsp;&nbsp;</code><code class="python keyword">if</code> <code class="python plain">item &gt; m </code><code class="python keyword">and</code> <code class="python plain">random() &gt; </code><code class="python value">1</code> <code class="python keyword">-</code> <code class="python plain">q:</code></div><div class="line number6 index5 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python comments"># Increment the step size if and only if the estimate keeps moving in</code></div><div class="line number7 index6 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python comments"># the same direction. Step size is incremented by the result of applying</code></div><div class="line number8 index7 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python comments"># the specified step function to the previous step size.</code></div><div class="line number9 index8 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">step </code><code class="python keyword">+</code><code class="python keyword">=</code> <code class="python plain">f(step) </code><code class="python keyword">if</code> <code class="python plain">sign &gt; </code><code class="python value">0</code> <code class="python keyword">else</code> <code class="python keyword">-</code><code class="python value">1</code> <code class="python keyword">*</code> <code class="python plain">f(step)</code></div><div class="line number10 index9 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python comments"># Increment the estimate by step size if step is positive. Otherwise,</code></div><div class="line number11 index10 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python comments"># increment the step size by one.</code></div><div class="line number12 index11 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">m </code><code class="python keyword">+</code><code class="python keyword">=</code> <code class="python plain">step </code><code class="python keyword">if</code> <code class="python plain">step &gt; </code><code class="python value">0</code> <code class="python keyword">else</code> <code class="python value">1</code></div><div class="line number13 index12 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python comments"># Mark that the estimate increased this step</code></div><div class="line number14 index13 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">sign </code><code class="python keyword">=</code> <code class="python value">1</code></div><div class="line number15 index14 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python comments"># If the estimate overshot the item in the stream, pull the estimate back</code></div><div class="line number16 index15 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python comments"># and re-adjust the step size.</code></div><div class="line number17 index16 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python keyword">if</code> <code class="python plain">m &gt; item:</code></div><div class="line number18 index17 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">step </code><code class="python keyword">+</code><code class="python keyword">=</code> <code class="python plain">(item </code><code class="python keyword">-</code> <code class="python plain">m)</code></div><div class="line number19 index18 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">m </code><code class="python keyword">=</code> <code class="python plain">item</code></div><div class="line number20 index19 alt1"><code class="python spaces">&nbsp;&nbsp;</code><code class="python comments"># If the item is less than the stream, follow all of the same steps as</code></div><div class="line number21 index20 alt2"><code class="python spaces">&nbsp;&nbsp;</code><code class="python comments"># above, with signs reversed.</code></div><div class="line number22 index21 alt1"><code class="python spaces">&nbsp;&nbsp;</code><code class="python keyword">elif</code> <code class="python plain">item &lt; m </code><code class="python keyword">and</code> <code class="python plain">random() &gt; q:</code></div><div class="line number23 index22 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">step </code><code class="python keyword">+</code><code class="python keyword">=</code> <code class="python plain">f(step) </code><code class="python keyword">if</code> <code class="python plain">sign &lt; </code><code class="python value">0</code> <code class="python keyword">else</code> <code class="python keyword">-</code><code class="python value">1</code> <code class="python keyword">*</code> <code class="python plain">f(step)</code></div><div class="line number24 index23 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">m </code><code class="python keyword">-</code><code class="python keyword">=</code> <code class="python plain">step </code><code class="python keyword">if</code> <code class="python plain">step &gt; </code><code class="python value">0</code> <code class="python keyword">else</code> <code class="python value">1</code></div><div class="line number25 index24 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">sign </code><code class="python keyword">=</code> <code class="python keyword">-</code><code class="python value">1</code></div><div class="line number26 index25 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python keyword">if</code> <code class="python plain">m &lt; item:</code></div><div class="line number27 index26 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">step </code><code class="python keyword">+</code><code class="python keyword">=</code> <code class="python plain">(m </code><code class="python keyword">-</code> <code class="python plain">item)</code></div><div class="line number28 index27 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">m </code><code class="python keyword">=</code> <code class="python plain">item</code></div><div class="line number29 index28 alt2"><code class="python spaces">&nbsp;&nbsp;</code><code class="python comments"># Damp down the step size to avoid oscillation.</code></div><div class="line number30 index29 alt1"><code class="python spaces">&nbsp;&nbsp;</code><code class="python keyword">if</code> <code class="python plain">(m </code><code class="python keyword">-</code> <code class="python plain">item) </code><code class="python keyword">*</code> <code class="python plain">sign &lt; </code><code class="python value">0</code> <code class="python keyword">and</code> <code class="python plain">step &gt; </code><code class="python value">1</code><code class="python plain">:</code></div><div class="line number31 index30 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">step </code><code class="python keyword">=</code> <code class="python value">1</code></div></div></td></tr></tbody></table></div></div>
<p>You can play around with the 1U and 2U algorithms in the simulation below.</p>
<div id="attachment_4435" style="width: 729px" class="wp-caption aligncenter"><a href="http://content.research.neustar.biz/blog/frugal.html"><img src="./Streaming Algorithms – Research_files/frugal_sim.png" width="719" height="704"></a><p class="wp-caption-text">Click above to run the Frugal Streaming simulation</p></div>
<p>As usual, there are a few interesting tidbits as well. If you read the paper you will see that they define the updates to <em>step</em> as a function. This means they are allowing many different types of increments to <em>step</em>. For example, instead of increasing the size of <em>step</em> by 1 each time we could increase it by 10 or even have it increase multiplicatively. They do talk about some uses of different updates to <em>step</em> but there is no analysis around this (yet) and they restrict all of the work in the paper to <em>step</em> increments of 1. We offer a few different <em>step</em> update functions in the simulation and they indeed do interesting things. Further exploration is definitely needed to get some insights here.</p>
<p>A non-obvious thing about the <em>step</em> variable is how it behaves under decrements. My initial thought was that <em>step</em> would get large if your current estimate was far below the actual value (thus allowing you to approach it faster from below) and that <em>step</em> would get to be a large negative number if your current estimate was very far above the actual value. This turns out to just be flat wrong. The negative updates to <em>step</em> have the effect of <em>stabilizing</em> the estimate (notice when step is negative that the updates to your estimates are always ± 1 ). If you read the algorithm closely you will see that <em>step</em> decrements when you consistently alternate up and down updates. This behavior occurs when the estimate is close to the actual value which causes <em>step</em> to become a very large negative number. And I mean VERY large. In practice we have seen this number as small as <img src="./Streaming Algorithms – Research_files/latex(4).php" alt="-10^{102}" title="-10^{102}" class="latex"> for some simulations.</p>
<h3>Monitoring</h3>
<p>One of the first things I thought of when I saw this sketch was to use it as a monitoring tool. Specifically, perhaps it could be used to replace the monitoring we use on our application server response times. It turns out that using this sketch for monitoring introduces some very interesting issues. So far, we have mostly talked about what I will call “static streams”. These are streams that have data in them which is pulled consistently from some static underlying distribution (as in the examples above). However, what if the underlying distribution changes? For example, what if one of our servers all of the sudden starts responding with slower response times? Does this frugal sketch enable you to <em>quickly</em> figure out that something has broken and fire off an alarm with <em>high confidence</em>? Well, in some ways this is an identical problem to cold start: how long does it take for an initial guess to reach a stable quantile? Unfortunately, there is no easy way to know when you have reached “equilibrium” and this makes identifying when an underlying distribution change has occurred difficult as well. The paper ends with an open challenge:</p>
<blockquote><p>… as our experiments and insights indicate, frugal streaming algorithms work with so little memory of the past that they are adaptable to changes in the stream characteristics. It will be of great interest to understand this phenomenon better.</p></blockquote>
<p>The paper shows some interesting experiments with changing data, but I agree with Qiang: we need to understand these algorithms better before I swap out all of our server monitoring tools (and our ops team would kill me). However, since these are so simple to implement and so small, we can easily deploy a few tests and see how the results compare “in the field” (you can play around with this by changing the underlying stream distribution in our simulation above.)</p>
<h3>Conclusion</h3>
<p>The frugal quantile algorithms proposed in the paper are fascinating. It is a very interesting turn in the sketching literature and Qiang and Muthu’s creativity really comes across. I am very interested in getting some real world uses out of this sketch and am excited to see what other applications we (and Qiang!) can think of. &nbsp;Many thanks to <a href="http://www.cs.rutgers.edu/~muthu/">Muthu</a>,&nbsp;<a href="http://paul.rutgers.edu/~qma/">Qiang Ma</a>&nbsp;and Jeremie Lumbroso for all their help!</p>
<h3>Appendix</h3>
<ul>
<li><strong>Variability</strong>: While the bounds on the accuracy of these algorithms seem wide to me, clearly in real world experiments we see much better performance than the guaranteed bounds in the paper.  In fact, the error bounds in the paper are dependent on the size of the stream and not fixed.</li>
<li>Size of step: A potential gotcha is the size of the step variable. Depending on your update function it indeed seems possible for this value to get below -MAXINT. Clearly a real implementation would need some error checking.</li>
<li><strong>Cold Start</strong>: One more gotcha is that you have no real way of knowing when you are near the quantile in question. For instance, starting your estimate at zero and measuring a true median which is 100,000,000,000 will take a long time to “catch up” to this value. There are a few ways to limit this, some of which are discussed in the paper. One way is to try and make a sane guess up front (especially if you know something about the distribution) and another is to start your guess with the value from the last counter. For instance, suppose you are in a monitoring situation and you are computing means over the course of a day. It would make sense to start tomorrow’s estimate with yesterdays final value.</li>
<li><strong>Accuracy</strong>: &nbsp;And, lastly, there is some interesting dependence on “atomicity”. Meaning, the estimates in some sense depend on how “large” the actual values are. In both, your minimum step size is 1. If my median in the stream is, say, 6 then this “atomic” update of 1 causes high relative fluctuation. It seems in real world examples you would like to balance the size of the thing you are estimating with the speed of approach of the algorithm. This could lead you to estimate latencies in microseconds rather than milliseconds for instance. All of this points to the fact that there are a bunch of real world engineering questions that need to be answered and thought about before you actually go and implement a million frugal sketches throughout your organization.</li>
</ul>
</div><div class="post-meta"><span class="categories">Filed Under: <a href="http://research.neustar.biz/category/data-science/" rel="category tag">Data Science</a>, <a href="http://research.neustar.biz/category/data-science/sketch-of-the-day/" rel="category tag">Sketch of the Day</a></span> <span class="tags">Tagged With: <a href="http://research.neustar.biz/tag/big-data/" rel="tag">Big Data</a>, <a href="http://research.neustar.biz/tag/data-science/" rel="tag">Data Science</a>, <a href="http://research.neustar.biz/tag/probabilistic-sketching/" rel="tag">Probabilistic Sketching</a>, <a href="http://research.neustar.biz/tag/real-time-streaming/" rel="tag">Real-time streaming</a>, <a href="http://research.neustar.biz/tag/sketching/" rel="tag">Sketching</a>, <a href="./Streaming Algorithms – Research_files/Streaming Algorithms – Research.html" rel="tag">Streaming Algorithms</a></span></div></div><div class="post-4204 post type-post status-publish format-standard hentry category-data-science category-general tag-big-data tag-data-science tag-dv-sketch tag-probabilistic-sketching tag-streaming-algorithms entry"><h2 class="entry-title"><a href="http://research.neustar.biz/2013/06/25/data-science-summit-update/" title="Data Science Summit – Update" rel="bookmark">Data Science Summit –&nbsp;Update</a></h2> 
<div class="post-info"><span class="date published time" title="2013-06-25T12:42:23+00:00">June 25, 2013</span>  by <span class="author vcard"><span class="fn"><a href="http://research.neustar.biz/author/wwkae/" title="mattcurcio" rel="author">mattcurcio</a></span></span> <span class="post-comments"><a href="http://research.neustar.biz/2013/06/25/data-science-summit-update/#comments">1 Comment</a></span> </div><div class="entry-content"><p>I don’t think I’m going out on a limb saying that our <a href="http://blog.aggregateknowledge.com/2013/05/23/foundation-capital-and-aggregate-knowledge-sponsor-streamingsketching-conference/">conference</a> last week was a success. Thanks to everyone who attended and thanks again to all the speakers. <a href="http://www.cs.rutgers.edu/~muthu/">Muthu</a> actually beat us to it and wrote up a nice <a href="http://mysliceofpizza.blogspot.com/2013/06/data-science-summit-in-sf.html">summary</a>. Very kind words from a great guy. For those of you that couldn’t make it (or those that want to relive the fun) we <a href="http://blog.aggregateknowledge.com/ak-data-science-summit-june-20-2013" target="_blank">posted the videos and slides</a>. Thanks again to everyone for making it such a success!</p>
<div id="attachment_4209" style="width: 682px" class="wp-caption aligncenter"><a href="http://agkn.files.wordpress.com/2013/06/p1010510.jpg"><img class=" wp-image-4209" alt="P1010510" src="./Streaming Algorithms – Research_files/p1010510.jpg" width="672" height="504"></a><p class="wp-caption-text">Muthu being Muthu during David Woodruff’s fantastic talk on streaming linear algebra</p></div>
</div><div class="post-meta"><span class="categories">Filed Under: <a href="http://research.neustar.biz/category/data-science/" rel="category tag">Data Science</a>, <a href="http://research.neustar.biz/category/general/" rel="category tag">General</a></span> <span class="tags">Tagged With: <a href="http://research.neustar.biz/tag/big-data/" rel="tag">Big Data</a>, <a href="http://research.neustar.biz/tag/data-science/" rel="tag">Data Science</a>, <a href="http://research.neustar.biz/tag/dv-sketch/" rel="tag">DV Sketch</a>, <a href="http://research.neustar.biz/tag/probabilistic-sketching/" rel="tag">Probabilistic Sketching</a>, <a href="./Streaming Algorithms – Research_files/Streaming Algorithms – Research.html" rel="tag">Streaming Algorithms</a></span></div></div><div class="post-4019 post type-post status-publish format-standard hentry category-data-science category-general tag-big-data tag-data-science tag-dv-sketch tag-probabilistic-sketching tag-streaming-algorithms entry"><h2 class="entry-title"><a href="http://research.neustar.biz/2013/05/23/foundation-capital-and-aggregate-knowledge-sponsor-streamingsketching-conference/" title="Foundation Capital and Aggregate Knowledge Sponsor Streaming/Sketching Conference" rel="bookmark">Foundation Capital and Aggregate Knowledge Sponsor Streaming/Sketching Conference</a></h2> 
<div class="post-info"><span class="date published time" title="2013-05-23T14:22:00+00:00">May 23, 2013</span>  by <span class="author vcard"><span class="fn"><a href="http://research.neustar.biz/author/wwkae/" title="mattcurcio" rel="author">mattcurcio</a></span></span> <span class="post-comments"><a href="http://research.neustar.biz/2013/05/23/foundation-capital-and-aggregate-knowledge-sponsor-streamingsketching-conference/#comments">9 Comments</a></span> </div><div class="entry-content"><p>We, along with our friends at Foundation Capital, are pleased to announce a 1 day mini-conference on streaming and sketching algorithms in Big Data. &nbsp;We have gathered an amazing group of speakers from academia and industry to give talks. &nbsp;If you are a reader of this blog we would love to have you come! &nbsp;The conference will be on 6/20 (Thursday) from 10 AM to 5:30 PM at the <a href="http://www.111minnagallery.com/">111 Minna Gallery</a> in San Francisco and attendance is limited. Breakfast and lunch included!</p>
<p>There will also be a happy hour afterwards if you cannot make the conference or just want a beer. &nbsp;</p>
<p>The speaker list includes:</p>
<h5>Muthu Muthukrishnan</h5>
<p>The Count-Min Sketch, 10 Years Later</p>
<p><em>The Count-Min Sketch is a data structure for indexing data streams in very small space. In a decade since its introduction, it has found many uses in theory and practice, with data streaming systems and beyond. This talk will survey the developments.</em></p>
<p><a href="http://www.cs.rutgers.edu/~muthu/">Muthu Muthukrishnan</a> is a Professor at Rutgers University and a Research Scientist at Microsoft, India. His research interest is in development of data stream theory and systems, as well as online advertising systems.</p>
<h5>David P. Woodruff</h5>
<p>Sketching as a Tool for Numerical Linear Algebra</p>
<p><em> The talk will focus on how sketching techniques from the data stream literature can be used to speed up well-studied algorithms for problems occurring in numerical linear algebra, such as least squares regression and approximate singular value decomposition. It will also discuss how they can be used to achieve very efficient algorithms for variants of these problems, such as robust regression.<br>
</em></p>
<p><a href="http://researcher.watson.ibm.com/researcher/view.php?person=us-dpwoodru">David Woodruff</a> joined the algorithms and complexity group at IBM Almaden in 2007 after completing his Ph.D. at MIT in theoretical computer science. His interests are in compressed sensing, communication, numerical linear algebra, sketching, and streaming.</p>
<h5>Sam Ritchie</h5>
<p>Summingbird: Streaming Map/Reduce at Twitter<br>
<em><br>
Summingbird is a platform for streaming map/reduce used at Twitter to build aggregations in real-time or on hadoop. When the programmer describes her job, that job can be run without change on Storm or Hadoop. Additionally, summingbird can manage merging realtime/online computations with offline batches so that small errors in real-time do not accumulate. Put another way, summingbird gives eventual consistency in a manner that is easy for the programmer to reason about.<br>
</em></p>
<p><a href="https://twitter.com/sritchie">Sam Ritchie</a> works on data analysis and infrastructure problems in Twitter’s Revenue engineering team. He is co-author of a number of open-source Scala and Clojure libraries, including Bijection, Algebird, Cascalog 2 and ElephantDB. He holds a bachelor’s degree in mechanical and aerospace engineering.</p>
<h5>Alexandr Andoni</h5>
<p>Similarity Search Algorithms<br>
<em><br>
Nearest Neighbor Search is an ubiquitous problem in analyzing massive datasets: its goal is to process a set of objects (such as images), so that later, one can find the object most similar to a given query object. I will survey the state-of-the-art for this problem, starting from the (Kanellakis-award winning) technique of Locality Sensitive Hashing, to its more modern relatives, and touch upon connection to the theory of sketching.<br>
</em></p>
<p><a href="http://research.microsoft.com/en-us/people/andoni/">Alexandr Andoni</a> is a researcher in the Microsoft Research at Silicon Valley since 2010, after finishing his PhD in MIT’s theory group and year-long postdoctoral position at Princeton University. His research interests revolve around algorithms for massive datasets, including similarity search and streaming/sublinear algorithms, as well as theoretical machine learning.</p>
<p>There will be a panel discussion on the topic of harboring research in startups. Speakers include:<br>
<a href="http://www.linkedin.com/in/peterskomoroch">Pete Skomoroch</a> from the LinkedIn data science team.<br>
<a href="http://www.linkedin.com/pub/rob-grzywinski/0/31/26b">Rob Grzywinski</a> of Aggregate Knowledge.<br>
<a href="http://www.linkedin.com/in/turian">Joseph Turian</a> of Metaoptimize </p>
<h5>Lightning talks</h5>
<ul>
<li>Armon Dadgar (Kiip) –&nbsp;Sketching Data Structures at Kiip
</li><li>Blake Mizerany (Heroku) –&nbsp;An Engineer Reads a Data Sketch
</li><li>Timon Karnezos (AK) –&nbsp;<strong>TBD</strong></li>
<li>Jérémie Lumbroso (INRIA) –&nbsp;Philippe Flajolet’s Contribution to Streaming Algorithms</li>
</ul>
<p><em>Update!</em> We <a href="http://blog.aggregateknowledge.com/ak-data-science-summit-june-20-2013" target="_blank">posted the videos and slides</a> for those of you that couldn’t make it (or those that want to relive the fun). Enjoy!</p>
</div><div class="post-meta"><span class="categories">Filed Under: <a href="http://research.neustar.biz/category/data-science/" rel="category tag">Data Science</a>, <a href="http://research.neustar.biz/category/general/" rel="category tag">General</a></span> <span class="tags">Tagged With: <a href="http://research.neustar.biz/tag/big-data/" rel="tag">Big Data</a>, <a href="http://research.neustar.biz/tag/data-science/" rel="tag">Data Science</a>, <a href="http://research.neustar.biz/tag/dv-sketch/" rel="tag">DV Sketch</a>, <a href="http://research.neustar.biz/tag/probabilistic-sketching/" rel="tag">Probabilistic Sketching</a>, <a href="./Streaming Algorithms – Research_files/Streaming Algorithms – Research.html" rel="tag">Streaming Algorithms</a></span></div></div><div class="post-3971 post type-post status-publish format-standard hentry category-data-science category-general tag-analytics tag-big-data tag-intern tag-programming-2 tag-streaming-algorithms entry"><h2 class="entry-title"><a href="http://research.neustar.biz/2013/05/09/call-for-summer-interns/" title="Call for Summer Interns" rel="bookmark">Call for Summer&nbsp;Interns</a></h2> 
<div class="post-info"><span class="date published time" title="2013-05-09T12:59:54+00:00">May 9, 2013</span>  by <span class="author vcard"><span class="fn"><a href="http://research.neustar.biz/author/rgrzywinski/" title="rgrzywinski" rel="author">rgrzywinski</a></span></span> <span class="post-comments"><a href="http://research.neustar.biz/2013/05/09/call-for-summer-interns/#respond">Leave a Comment</a></span> </div><div class="entry-content"><p>AK is looking for a summer intern in our R&amp;D group. If any of our blog posts have interested you, then you’ll fit right in!</p>
<p>We’re looking for someone who has a good handle on a few programming languages (pick any two from R/Mathematica/Python/Javascript/Java) and has some math in their background — college-level calculus or algebra is plenty. Ideally, you’re interested in learning about:</p>
<ul>
<li>building and tuning high-performance data structures,</li>
<li>streaming algorithms,</li>
<li>interesting data visualizations, and</li>
<li>how to translate academic research into business value.</li>
</ul>
<p>It’s OK if you’ve never seen the stuff we write about on the blog before! We didn’t either until we started researching them!</p>
<p>I can’t emphasize this enough: <em>we don’t expect you to know how to do the things above yet</em>. We simply expect you to have a passion for learning about them and the diligence to work through what (at the time) seem like impossible problems. Work experience is nice, but not necessary. As long as you can write clean code and can work hard, you’re well-qualified for this job.</p>
<p>If you’re interested, please send a brief note about why you’re interested, along with a CV and/or GitHub username to <strong>timon at aggregateknowledge dot com</strong>. For extra credit, please submit one (or more!) of the following:</p>
<ul>
<li><span style="line-height:13px;">An implementation of HLL, Count-Min Sketch, K-Min Values, or Distinct Sampling in a language of your choice.</span></li>
<li>An extension to <a href="http://blog.aggregateknowledge.com/2012/02/02/choosing-a-good-hash-function-part-3/" target="_blank">Colin’s blog post about a good hash function</a>&nbsp;that adds CityHash and SipHash to the shoot-out.</li>
<li>An explanation of the tradeoffs between using a hash map and Count-Min Sketch for counting item frequency.</li>
</ul>
<p>(I feel like I shouldn’t have to say this, but yes, these are all answered somewhere on the internet. Don’t plagiarize. What we want is for you to go learn from them and try your own hand at implementing/experimenting. Also, don’t freak out, these are extra credit!)</p>
</div><div class="post-meta"><span class="categories">Filed Under: <a href="http://research.neustar.biz/category/data-science/" rel="category tag">Data Science</a>, <a href="http://research.neustar.biz/category/general/" rel="category tag">General</a></span> <span class="tags">Tagged With: <a href="http://research.neustar.biz/tag/analytics/" rel="tag">Analytics</a>, <a href="http://research.neustar.biz/tag/big-data/" rel="tag">Big Data</a>, <a href="http://research.neustar.biz/tag/intern/" rel="tag">Intern</a>, <a href="http://research.neustar.biz/tag/programming-2/" rel="tag">programming</a>, <a href="./Streaming Algorithms – Research_files/Streaming Algorithms – Research.html" rel="tag">Streaming Algorithms</a></span></div></div><div class="post-3340 post type-post status-publish format-standard hentry category-general tag-presentation tag-sketch tag-streaming-algorithms entry"><h2 class="entry-title"><a href="http://research.neustar.biz/2013/02/26/the-sketching-press/" title="The Sketching Press" rel="bookmark">The Sketching Press</a></h2> 
<div class="post-info"><span class="date published time" title="2013-02-26T16:06:39+00:00">February 26, 2013</span>  by <span class="author vcard"><span class="fn"><a href="http://research.neustar.biz/author/wwkae/" title="mattcurcio" rel="author">mattcurcio</a></span></span> <span class="post-comments"><a href="http://research.neustar.biz/2013/02/26/the-sketching-press/#respond">Leave a Comment</a></span> </div><div class="entry-content"><p style="text-align:center;"><a href="http://agkn.files.wordpress.com/2013/02/bahman.png"><img class="aligncenter  wp-image-3343" alt="bahman" src="./Streaming Algorithms – Research_files/bahman.png" width="690" height="535"></a></p>
<p>Yesterday we had a visitor at the office, <a href="http://strataconf.com/strata2013/public/schedule/speaker/138711">Bahman Bahmani</a>. He was nice enough to give us a preview of his <a href="http://strataconf.com/strata2013/public/schedule/detail/27311">talk</a> for <a href="http://strataconf.com/">Strata</a> this week. As we are sketching cheerleaders, it was really cool of him to let us see his talk and to trade some war stories. If you are at Strata this week, definitely go and check it out. He has some really cool <a href="http://strata.oreilly.com/2013/02/sketching-techniques-for-real-time-big-data.html">examples</a> of sketching applications and a detailed description of his work at Twitter for their streaming PageRank sketch.</p>
</div><div class="post-meta"><span class="categories">Filed Under: <a href="http://research.neustar.biz/category/general/" rel="category tag">General</a></span> <span class="tags">Tagged With: <a href="http://research.neustar.biz/tag/presentation/" rel="tag">Presentation</a>, <a href="http://research.neustar.biz/tag/sketch/" rel="tag">Sketch</a>, <a href="./Streaming Algorithms – Research_files/Streaming Algorithms – Research.html" rel="tag">Streaming Algorithms</a></span></div></div><div class="post-2947 post type-post status-publish format-standard hentry category-general tag-agile-analytics tag-analytics tag-dv-sketch tag-hll tag-hyperloglog tag-probabilistic-sketching tag-real-time-streaming tag-set-intersection tag-sketching tag-streaming tag-streaming-algorithms entry"><h2 class="entry-title"><a href="http://research.neustar.biz/2012/12/17/hll-intersections-2/" title="HLL Intersections" rel="bookmark">HLL Intersections</a></h2> 
<div class="post-info"><span class="date published time" title="2012-12-17T13:56:54+00:00">December 17, 2012</span>  by <span class="author vcard"><span class="fn"><a href="http://research.neustar.biz/author/timonk/" title="timonk" rel="author">timonk</a></span></span> <span class="post-comments"><a href="http://research.neustar.biz/2012/12/17/hll-intersections-2/#comments">8 Comments</a></span> </div><div class="entry-content"><h3>Why?</h3>
<p>The intersection of two streams (of user ids) is a particularly important business need in the advertising industry. For instance, if you want to reach suburban moms but the cost of targeting those women on a particular inventory provider is too high, you might want to know about a cheaper inventory provider whose audience overlaps with the first provider. You may also want to know how heavily your car-purchaser audience overlaps with a certain metro area or a particular income range. These types of operations are critical for understanding where and how well you’re spending your advertising budget.</p>
<p>As we’ve seen before, <a href="http://blog.aggregateknowledge.com/2012/10/25/sketch-of-the-day-hyperloglog-cornerstone-of-a-big-data-infrastructure/" target="_blank">HyperLogLog</a> provides a time- and memory-efficient algorithm for estimating the number of distinct values in a stream. For the past two years, we’ve been using HLL at AK to do just that: count the number of unique users in a stream of ad impressions. Conveniently, HLL also supports the union operator ( <img src="./Streaming Algorithms – Research_files/latex(5).php" alt="\cup" title="\cup" class="latex"> ) allowing us to trivially estimate the distinct value count of any composition of streams without sacrificing precision or accuracy. This piqued our interest because if we can “losslessly” compute the union of two streams and produce low-error cardinality estimates, then there’s a chance we can use that estimate along with the <a href="http://en.wikipedia.org/wiki/Inclusion%E2%80%93exclusion_principle" target="_blank">inclusion-exclusion principle</a> to produce “directionally correct” cardinality estimates of the&nbsp;<em>intersection of two streams</em>. (To be clear, when I say “directionally correct” my criteria is “can an advertiser make a decision off of this number?”, or “can it point them in the right direction for further research?”. This often means that we can tolerate relative errors of up to 50%.)</p>
<p>The goals were:</p>
<ol>
<li>Get a grasp on the theoretical error bounds of intersections done with HLLs, and</li>
<li>Come up with heuristic bounds around <img src="./Streaming Algorithms – Research_files/latex(6).php" alt="m" title="m" class="latex">, <img src="./Streaming Algorithms – Research_files/latex(7).php" alt="overlap" title="overlap" class="latex">, and the set cardinalities that could inform our usage of HLL intersections in the AK product.</li>
</ol>
<p>Quick terminology review:</p>
<ul>
<li>If I have set of integers <img src="./Streaming Algorithms – Research_files/latex(8).php" alt="A" title="A" class="latex">, I’m going to call the HLL representing it <img src="./Streaming Algorithms – Research_files/latex(9).php" alt="H_{A}" title="H_{A}" class="latex">.</li>
<li>If I have HLLs <img src="./Streaming Algorithms – Research_files/latex(10).php" alt="H_{A}, H_{B}" title="H_{A}, H_{B}" class="latex"> and their union <img src="./Streaming Algorithms – Research_files/latex(11).php" alt="H_{A \cup B}" title="H_{A \cup B}" class="latex">, then I’m going to call the intersection cardinality estimate produced <img src="./Streaming Algorithms – Research_files/latex(12).php" alt="|H_{A \cap B}|" title="|H_{A \cap B}|" class="latex">.</li>
<li>Define the <img src="./Streaming Algorithms – Research_files/latex(7).php" alt="overlap" title="overlap" class="latex"> between two sets as <img src="./Streaming Algorithms – Research_files/latex(13).php" alt="overlap(A, B) := \frac{|A \cap B|}{min(|A|, |B|)}" title="overlap(A, B) := \frac{|A \cap B|}{min(|A|, |B|)}" class="latex">.</li>
<li>Define the cardinality ratio <img src="./Streaming Algorithms – Research_files/latex(14).php" alt="\frac{max(|A|, |B|)}{min(|A|, |B|)}" title="\frac{max(|A|, |B|)}{min(|A|, |B|)}" class="latex"> as a shorthand for the relative cardinality of the two sets.</li>
<li>We’ll represent the <a href="http://en.wikipedia.org/wiki/Absolute_error" target="_blank">absolute error</a>&nbsp;of an observation <img src="./Streaming Algorithms – Research_files/latex(15).php" alt="|H_{A}|" title="|H_{A}|" class="latex"> as <img src="./Streaming Algorithms – Research_files/latex(16).php" alt="\Delta |H_{A}|" title="\Delta |H_{A}|" class="latex">.</li>
</ul>
<p>That should be enough for those following our recent posts, but for those just jumping in, check out Appendices A and B at the bottom of the post for a more thorough review of the set terminology and error terminology.</p>
<h3>Experiment</h3>
<p>We fixed 16 <img src="./Streaming Algorithms – Research_files/latex(7).php" alt="overlap" title="overlap" class="latex">&nbsp;values (0.0001, 0.001, 0.01, 0.02, 0.05, 0.1, 0.15, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0) and 12 set cardinalities (100M, 50M, 10M, 5M, 1M, 500K, 100K, 50K, 10K, 5K, 1K, 300) and did 100 runs of each permutation of <img src="./Streaming Algorithms – Research_files/latex(17).php" alt="(overlap, |A|, |B|)" title="(overlap, |A|, |B|)" class="latex">.&nbsp;A random stream of 64-bit integers hashed with <a href="https://sites.google.com/site/murmurhash/">Murmur3</a> was used to create the two sets such that they&nbsp;shared exactly <img src="./Streaming Algorithms – Research_files/latex(18).php" alt="min(|A|,|B|) \cdot overlap = |A \cap B|" title="min(|A|,|B|) \cdot overlap = |A \cap B|" class="latex"> &nbsp;elements. We then built the corresponding HLLs <img src="./Streaming Algorithms – Research_files/latex(9).php" alt="H_{A}" title="H_{A}" class="latex"> and <img src="./Streaming Algorithms – Research_files/latex(19).php" alt="H_{B}" title="H_{B}" class="latex"> for those sets and calculated the <em>intersection cardinality estimate&nbsp;</em><img src="./Streaming Algorithms – Research_files/latex(20).php" alt="|H_{A} \cap H_{B}|" title="|H_{A} \cap H_{B}|" class="latex"> and computed its relative error.</p>
<p>Given that we could only generate and insert about 2M elements/second per core, doing runs with set cardinalities greater than 100M was quickly ruled out for this blog post. However, I can assure you the results hold for much larger sets (up to the multiple billion-element range) as long as you heed the advice below.</p>
<h3>Results</h3>
<p>This first group of plots has a lot going on, so I’ll preface it by saying that it’s just here to give you a general feeling for what’s going on.&nbsp;First note that within each group of boxplots <img src="./Streaming Algorithms – Research_files/latex(7).php" alt="overlap" title="overlap" class="latex"> increases from left to right (orange to green to pink), and within each plot cardinality ratio increases from left to right. Also note that the y-axis (the relative error of the observation) is log-base-10 scale. You can clearly see that as the set sizes diverge, the error skyrockets for all but the most similar (in both cardinality and composition) sets. I’ve drawn in a horizontal line at 50% relative error to make it easier to see what falls under the “directionally correct” criteria. You can (and should) click for a full-sized image.</p>
<p><strong>Note:&nbsp;</strong>the error bars narrow as we progress further to the right because there are fewer observations with very large cardinality ratios. This is an artifact of the experimental design.</p>
<p style="text-align:center;"><a href="http://agkn.files.wordpress.com/2012/12/interare_vs_cardf_all_2400.png" target="_blank"><img class="aligncenter size-full wp-image-3035" title="HLL Intersection Cardinality Relative Error (All Parameters)" alt="interAre_vs_cardF_all_800" src="./Streaming Algorithms – Research_files/interare_vs_cardf_all_800.png"></a></p>
<p>A few things jump out immediately:</p>
<ul>
<li>For cardinality ratio &gt; 500, the majority of observations have many thousands of percent error.</li>
<li>When cardinality ratio is smaller than that and <img src="./Streaming Algorithms – Research_files/latex(21).php" alt="overlap &gt; 0.4" title="overlap &gt; 0.4" class="latex">, register count has little effect on error, which stays very low.</li>
<li>When <img src="./Streaming Algorithms – Research_files/latex(22).php" alt="overlap \le 0.01" title="overlap \le 0.01" class="latex">, register count has little effect on error, which stays very high.</li>
</ul>
<p>Just eyeballing this, the lesson I get is that&nbsp;computing intersection cardinality with small error (relative to the true value) is difficult and only works within certain constraints. Specifically,</p>
<ol>
<li><img src="./Streaming Algorithms – Research_files/latex(23).php" alt="\frac{|A|}{|B|} &lt; 100" title="\frac{|A|}{|B|} &lt; 100" class="latex">, and</li>
<li><img src="./Streaming Algorithms – Research_files/latex(24).php" alt="overlap(A, B) = \frac{|A \cap B|}{min(|A|, |B|)} \ge 0.05" title="overlap(A, B) = \frac{|A \cap B|}{min(|A|, |B|)} \ge 0.05" class="latex">.</li>
</ol>
<p>The intuition behind this is very simple: if the error of any one of the terms in your calculation is roughly as large as the true value of the result then you’re not going to estimate that result well. Let’s look back at the <em>intersection cardinality</em>&nbsp;formula. The left-hand side (that we are trying to estimate) is a “small” value, usually. The three terms on the right tend to be “large” (or at least “larger”) values. If any of the “large” terms has error as large as the left-hand side we’re out of luck.</p>
<p style="text-align:center;"><a href="http://agkn.files.wordpress.com/2012/12/labeled_overlaps1.png" target="_blank" rel="http://agkn.files.wordpress.com/2012/12/labeled_overlaps1.png"><img class="aligncenter  wp-image-3045" alt="Overlap Examples" src="./Streaming Algorithms – Research_files/labeled_overlaps1.png" width="400" height="400"></a></p>
<p>So, let’s say you can compute the cardinality of an HLL with relative error of a few percent. If <img src="./Streaming Algorithms – Research_files/latex(15).php" alt="|H_{A}|" title="|H_{A}|" class="latex"> is two orders of magnitude smaller than <img src="./Streaming Algorithms – Research_files/latex(25).php" alt="|H_{B}|" title="|H_{B}|" class="latex">, then&nbsp;the<em> error alone </em>of <img src="./Streaming Algorithms – Research_files/latex(25).php" alt="|H_{B}|" title="|H_{B}|" class="latex"> is roughly as large as <img src="./Streaming Algorithms – Research_files/latex(26).php" alt="|A|" title="|A|" class="latex">.</p>
<p style="text-align:center;"><img src="./Streaming Algorithms – Research_files/latex(27).php" alt="|A \cap B| \le |A|" title="|A \cap B| \le |A|" class="latex"> by definition, so</p>
<p style="text-align:center;"><img src="./Streaming Algorithms – Research_files/latex(28).php" alt="|A \cap B| \le |A| \approx |H_{A}| \approx \Delta |H_{B}|" title="|A \cap B| \le |A| \approx |H_{A}| \approx \Delta |H_{B}|" class="latex">.</p>
<p>In the best scenario, where <img src="./Streaming Algorithms – Research_files/latex(29).php" alt="A \cap B = A" title="A \cap B = A" class="latex">, the errors of <img src="./Streaming Algorithms – Research_files/latex(25).php" alt="|H_{B}|" title="|H_{B}|" class="latex"> and <img src="./Streaming Algorithms – Research_files/latex(30).php" alt="|H_{A \cup B}| \approx |H_{B}|" title="|H_{A \cup B}| \approx |H_{B}|" class="latex"> are both roughly the same size as what you’re trying to measure. Furthermore, even if <img src="./Streaming Algorithms – Research_files/latex(31).php" alt="|A| \approx |B|" title="|A| \approx |B|" class="latex"> but the overlap is very small, then <img src="./Streaming Algorithms – Research_files/latex(32).php" alt="|A \cap B|" title="|A \cap B|" class="latex"> &nbsp;will be roughly as large as the error of all three right-hand terms.</p>
<h3>On the bubble</h3>
<p>Let’s throw out the permutations whose error bounds clearly don’t support “directionally correct” answers (<img src="./Streaming Algorithms – Research_files/latex(33).php" alt="overlap &lt; 0.01 " title="overlap &lt; 0.01 " class="latex"> and <img src="./Streaming Algorithms – Research_files/latex(34).php" alt="\frac{|A|}{|B|} &gt; 500 " title="\frac{|A|}{|B|} &gt; 500 " class="latex">) and those that trivially do (<img src="./Streaming Algorithms – Research_files/latex(35).php" alt="overlap &gt; 0.4 " title="overlap &gt; 0.4 " class="latex">) so we can focus more closely on the observations that are “on the bubble”. Sadly, these plots exhibit a good deal of variance inherent in their smaller sample size. Ideally we’d have tens of thousands of runs of each combination, but for now this rough sketch will hopefully be useful. (Apologies for the inconsistent colors between the two plots. It’s a real bear to coordinate these things in R.) Again, please click through for a larger, clearer image.</p>
<p style="text-align:center;"><a href="http://agkn.files.wordpress.com/2012/12/interare_vs_cardf_good_2400.png" target="_blank"><img class="aligncenter size-full wp-image-3037" title="HLL Intersection Cardinality Relative Error (Restricted Parameters)" alt="interAre_vs_cardF_good_800" src="./Streaming Algorithms – Research_files/interare_vs_cardf_good_800.png"></a></p>
<p>By doubling the number of registers, the variance of the relative error falls by about a quarter and moves the median relative error down (closer to zero) by 10-20 points.</p>
<p>In general, we’ve seen that the following cutoffs perform pretty well, practically. Note that some of these aren’t reflected too clearly in the plots because of the smaller sample sizes.</p>
<table>
<thead>
<tr>
<th>Register Count</th>
<th>Data Structure Size</th>
<th>Overlap Cutoff</th>
<th>Cardinality Ratio Cutoff</th>
</tr>
</thead>
<tbody>
<tr>
<td>8192</td>
<td>5kB</td>
<td>0.05</td>
<td>10</td>
</tr>
<tr>
<td>16384</td>
<td>10kB</td>
<td>0.05</td>
<td>20</td>
</tr>
<tr>
<td>32768</td>
<td>20kB</td>
<td>0.05</td>
<td>30</td>
</tr>
<tr>
<td>65536</td>
<td>41kB</td>
<td>0.05</td>
<td>100</td>
</tr>
</tbody>
</table>
<h3 style="text-align:justify;">Error Estimation</h3>
<p>To get a theoretical formulation of the error envelope for intersection, in terms of the two set sizes and their overlap, I tried the first and simplest error propagation technique I learned. For variables <img src="./Streaming Algorithms – Research_files/latex(36).php" alt="Y, Z, ..." title="Y, Z, ..." class="latex">, and <img src="./Streaming Algorithms – Research_files/latex(37).php" alt="X" title="X" class="latex"> a linear combination of those (independent) variables, we have</p>
<p style="text-align:center;"><img src="./Streaming Algorithms – Research_files/latex(38).php" alt="\Delta X = \sqrt{ (\Delta Y)^2 + (\Delta Z)^2 + ...}" title="\Delta X = \sqrt{ (\Delta Y)^2 + (\Delta Z)^2 + ...}" class="latex"></p>
<p style="text-align:left;">Applied to the inclusion-exclusion formula:</p>
<p style="text-align:center;"><img src="./Streaming Algorithms – Research_files/latex(39).php" alt="\begin{array}{ll} \displaystyle \Delta |H_{A \cap B}| &amp;= \sqrt{ (\Delta |H_{A}|)^2 + (\Delta |H_{B}|)^2 + (\Delta |H_{A \cup B}|)^2} \\ &amp;= \sqrt{ (\sigma\cdot |A|)^2 + (\sigma\cdot |B|)^2 + (\sigma\cdot |A \cup B|)^2} \end{array}" title="\begin{array}{ll} \displaystyle \Delta |H_{A \cap B}| &amp;= \sqrt{ (\Delta |H_{A}|)^2 + (\Delta |H_{B}|)^2 + (\Delta |H_{A \cup B}|)^2} \\ &amp;= \sqrt{ (\sigma\cdot |A|)^2 + (\sigma\cdot |B|)^2 + (\sigma\cdot |A \cup B|)^2} \end{array}" class="latex"></p>
<p style="text-align:center;">where</p>
<p style="text-align:center;"><img src="./Streaming Algorithms – Research_files/latex(40).php" alt="\sigma = \frac{1.04}{\sqrt{m}}" title="\sigma = \frac{1.04}{\sqrt{m}}" class="latex"> as in section 4 (“Discussion”) of the <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.142.9475" target="_blank">HLL paper</a>.</p>
<p style="text-align:left;"><strong>Aside:</strong>&nbsp;Clearly <img src="./Streaming Algorithms – Research_files/latex(41).php" alt="|H_{A \cup B}|" title="|H_{A \cup B}|" class="latex"> is not independent of <img src="./Streaming Algorithms – Research_files/latex(42).php" alt="|H_{A}| + |H_{B}|" title="|H_{A}| + |H_{B}|" class="latex">, though <img src="./Streaming Algorithms – Research_files/latex(15).php" alt="|H_{A}|" title="|H_{A}|" class="latex"> is likely independent of <img src="./Streaming Algorithms – Research_files/latex(25).php" alt="|H_{B}|" title="|H_{B}|" class="latex">. However, I do not know how to&nbsp;<em>a priori</em>&nbsp;calculate the covariance in order to use an error propagation model for dependent variables. If you do, please pipe up in the comments!</p>
<p style="text-align:left;">I’ve plotted this error envelope against the relative error of the observations from HLLs with 8192 registers (approximately 5kB data structure).</p>
<p style="text-align:center;"><a href="http://agkn.files.wordpress.com/2012/12/err_bounds_good_2400.png"><img class="aligncenter size-full wp-image-3033" alt="err_bounds_good_800" src="./Streaming Algorithms – Research_files/err_bounds_good_800.png"></a></p>
<p style="text-align:left;">Despite the crudeness of the method, it provided a 95% error envelope for the data without significant differences across cardinality ratio or <img src="./Streaming Algorithms – Research_files/latex(7).php" alt="overlap" title="overlap" class="latex">. Specifically, at least 95% of observations satisfied</p>
<p style="text-align:center;"><img src="./Streaming Algorithms – Research_files/latex(43).php" alt="(|H_{A \cap B}| - |A \cap B|) &lt; \Delta |H_{A \cap B}|" title="(|H_{A \cap B}| - |A \cap B|) &lt; \Delta |H_{A \cap B}|" class="latex"></p>
<p>However, it’s really only useful in the ranges shown in the table above. Past those cutoffs the bound becomes too loose and isn’t very useful.</p>
<p>This is particularly convenient because you can tune the number of registers you need to allocate based on the most common intersection sizes/overlaps you see in your application. Obviously, I’d recommend everyone run these tests and do this analysis on their business data, and not on some contrived setup for a blog post. We’ve definitely seen that we can get away with far less memory usage than expected to successfully power our features, simply because we tuned and experimented with our most common use cases.</p>
<h3>Next Steps</h3>
<p>We hope to improve the intersection cardinality result by finding alternatives to the inclusion-exclusion formula. We’ve tried a few different approaches, mostly centered around the idea of treating the register collections themselves as sets, and in my next post we’ll dive into those and other failed attempts!</p>
<hr>
<h3>Appendix A: A Review Of Sets</h3>
<p>Let’s say we have two streams of user ids, <img src="./Streaming Algorithms – Research_files/latex(44).php" alt="S_{A}" title="S_{A}" class="latex"> and <img src="./Streaming Algorithms – Research_files/latex(45).php" alt="S_{B}" title="S_{B}" class="latex">. Take a snapshot of the unique elements in those streams as sets and call them <img src="./Streaming Algorithms – Research_files/latex(8).php" alt="A" title="A" class="latex"> and <img src="./Streaming Algorithms – Research_files/latex(46).php" alt="B" title="B" class="latex">. In the standard notation, we’ll represent the cardinality, or number of elements, of each set as <img src="./Streaming Algorithms – Research_files/latex(26).php" alt="|A|" title="|A|" class="latex"> and <img src="./Streaming Algorithms – Research_files/latex(47).php" alt="|B|" title="|B|" class="latex">.</p>
<blockquote><p>Example: If <img src="./Streaming Algorithms – Research_files/latex(48).php" alt="A = \{1,2,10\}" title="A = \{1,2,10\}" class="latex"> then <img src="./Streaming Algorithms – Research_files/latex(49).php" alt="|A| = 3" title="|A| = 3" class="latex">.</p></blockquote>
<p>If I wanted to represent the unique elements in both of those sets combined as another set I would be performing the union, which is represented by <img src="./Streaming Algorithms – Research_files/latex(50).php" alt="A \cup B" title="A \cup B" class="latex">.</p>
<blockquote><p>Example: If <img src="./Streaming Algorithms – Research_files/latex(51).php" alt="A = \{1,2,3\}, B=\{2,3,4\}" title="A = \{1,2,3\}, B=\{2,3,4\}" class="latex"> then <img src="./Streaming Algorithms – Research_files/latex(52).php" alt="A \cup B = \{1,2,3,4\}" title="A \cup B = \{1,2,3,4\}" class="latex">.</p></blockquote>
<p>If I wanted to represent the unique elements that appear in both <img src="./Streaming Algorithms – Research_files/latex(8).php" alt="A" title="A" class="latex"> and <img src="./Streaming Algorithms – Research_files/latex(46).php" alt="B" title="B" class="latex"> I would be performing the intersection, which is represented by <img src="./Streaming Algorithms – Research_files/latex(53).php" alt="A \cap B" title="A \cap B" class="latex">.</p>
<blockquote><p>Example: With <img src="./Streaming Algorithms – Research_files/latex(54).php" alt="A, B" title="A, B" class="latex"> as above, <img src="./Streaming Algorithms – Research_files/latex(55).php" alt="A \cap B = \{2,3\}" title="A \cap B = \{2,3\}" class="latex">.</p></blockquote>
<p>The relationship between the union’s cardinality and the intersection’s cardinality is given by the inclusion-exclusion principle. (We’ll only be looking at the two-set version in this post.) For reference, the two-way inclusion-exclusion formula is <img src="./Streaming Algorithms – Research_files/latex(56).php" alt="|A \cap B| = |A| + |B| - |A \cup B| " title="|A \cap B| = |A| + |B| - |A \cup B| " class="latex">.</p>
<blockquote><p>Example: With <img src="./Streaming Algorithms – Research_files/latex(54).php" alt="A, B" title="A, B" class="latex"> as above, we see that <img src="./Streaming Algorithms – Research_files/latex(57).php" alt="|A \cap B| = 2" title="|A \cap B| = 2" class="latex"> and <img src="./Streaming Algorithms – Research_files/latex(58).php" alt="|A| + |B| - |A \cup B| = 3 + 3 - 4 = 2" title="|A| + |B| - |A \cup B| = 3 + 3 - 4 = 2" class="latex">.</p></blockquote>
<p>For convenience we’ll define the <img src="./Streaming Algorithms – Research_files/latex(7).php" alt="overlap" title="overlap" class="latex"> between two sets as <img src="./Streaming Algorithms – Research_files/latex(13).php" alt="overlap(A, B) := \frac{|A \cap B|}{min(|A|, |B|)}" title="overlap(A, B) := \frac{|A \cap B|}{min(|A|, |B|)}" class="latex">.</p>
<blockquote><p>Example: With <img src="./Streaming Algorithms – Research_files/latex(54).php" alt="A, B" title="A, B" class="latex"> as above, <img src="./Streaming Algorithms – Research_files/latex(59).php" alt="overlap(A,B) = \frac{|A \cap B|}{min(|A|, |B|)} = \frac{2}{min(3,3)} = \frac{2}{3}" title="overlap(A,B) = \frac{|A \cap B|}{min(|A|, |B|)} = \frac{2}{min(3,3)} = \frac{2}{3}" class="latex">.</p></blockquote>
<p>Similarly, for convenience, we’ll define the cardinality ratio <img src="./Streaming Algorithms – Research_files/latex(14).php" alt="\frac{max(|A|, |B|)}{min(|A|, |B|)}" title="\frac{max(|A|, |B|)}{min(|A|, |B|)}" class="latex"> as a shorthand for the relative cardinality of the two sets.</p>
<p>The examples and operators shown above are all relevant for exact, true values. However, HLLs do not provide exact answers to the set cardinality question. They offer estimates of the cardinality along with certain error guarantees about those estimates. In order to differentiate between the two, we introduce HLL-specific operators.</p>
<p>Consider a set <img src="./Streaming Algorithms – Research_files/latex(8).php" alt="A" title="A" class="latex">. Call the HLL constructed from this set’s elements <img src="./Streaming Algorithms – Research_files/latex(9).php" alt="H_{A}" title="H_{A}" class="latex">. The cardinality estimate given by the HLL algorithm for <img src="./Streaming Algorithms – Research_files/latex(9).php" alt="H_{A}" title="H_{A}" class="latex"> is <img src="./Streaming Algorithms – Research_files/latex(15).php" alt="|H_{A}|" title="|H_{A}|" class="latex">.</p>
<p>Define the union of two HLLs <img src="./Streaming Algorithms – Research_files/latex(60).php" alt="H_{A} \cup H_{B} := H_{A \cup B}" title="H_{A} \cup H_{B} := H_{A \cup B}" class="latex">, which is also the same as the HLL created by taking the pairwise max of <img src="./Streaming Algorithms – Research_files/latex(9).php" alt="H_{A}" title="H_{A}" class="latex">‘s and <img src="./Streaming Algorithms – Research_files/latex(19).php" alt="H_{B}" title="H_{B}" class="latex">‘s registers.</p>
<p>Finally, define the intersection cardinality of two HLLs in the obvious way: <img src="./Streaming Algorithms – Research_files/latex(61).php" alt="|H_{A} \cap H_{B}| := |H_{A}| + |H_{B}| - |H_{A \cup B}|" title="|H_{A} \cap H_{B}| := |H_{A}| + |H_{B}| - |H_{A \cup B}|" class="latex">. (This is simply the inclusion-exclusion formula for two sets with the cardinality estimates instead of the true values.)</p>
<h3>Appendix B: A (Very Brief) Review of Error</h3>
<p>The simplest way of understanding the error of an estimate is simply “how far is it from the truth?”. That is, what is the difference in value between the estimate and the exact value, also known as the <a href="http://en.wikipedia.org/wiki/Absolute_error" target="_blank">absolute error</a>.</p>
<p>However, that’s only useful if you’re only measuring a single thing over and over again. The primary criteria for judging the utility of HLL intersections is&nbsp;<em>relative error </em>because we are trying to measure intersections of many different sizes. In order to get an apples-to-apples comparison of the efficacy of our method, we normalize the absolute error by the true size of the intersection.&nbsp;So, for some observation <img src="./Streaming Algorithms – Research_files/latex(62).php" alt="\hat{x}" title="\hat{x}" class="latex"> whose exact value is non-zero <img src="./Streaming Algorithms – Research_files/latex(63).php" alt="x" title="x" class="latex">, we say that the relative error of the observation is <img src="./Streaming Algorithms – Research_files/latex(64).php" alt="\frac{x-\hat{x}}{x}" title="\frac{x-\hat{x}}{x}" class="latex">. That is, “by what percentage off the true value is the observation off?”</p>
<blockquote><p>Example: If <img src="./Streaming Algorithms – Research_files/latex(65).php" alt="|A| = 100, |H_{A}| = 90" title="|A| = 100, |H_{A}| = 90" class="latex"> then the relative error is <img src="./Streaming Algorithms – Research_files/latex(66).php" alt="\frac{100 - 90}{100} = \frac{10}{100} = 10\%" title="\frac{100 - 90}{100} = \frac{10}{100} = 10\%" class="latex">.</p></blockquote>
</div><div class="post-meta"><span class="categories">Filed Under: <a href="http://research.neustar.biz/category/general/" rel="category tag">General</a></span> <span class="tags">Tagged With: <a href="http://research.neustar.biz/tag/agile-analytics/" rel="tag">Agile Analytics</a>, <a href="http://research.neustar.biz/tag/analytics/" rel="tag">Analytics</a>, <a href="http://research.neustar.biz/tag/dv-sketch/" rel="tag">DV Sketch</a>, <a href="http://research.neustar.biz/tag/hll/" rel="tag">HLL</a>, <a href="http://research.neustar.biz/tag/hyperloglog/" rel="tag">HyperLogLog</a>, <a href="http://research.neustar.biz/tag/probabilistic-sketching/" rel="tag">Probabilistic Sketching</a>, <a href="http://research.neustar.biz/tag/real-time-streaming/" rel="tag">Real-time streaming</a>, <a href="http://research.neustar.biz/tag/set-intersection/" rel="tag">Set Intersection</a>, <a href="http://research.neustar.biz/tag/sketching/" rel="tag">Sketching</a>, <a href="http://research.neustar.biz/tag/streaming/" rel="tag">Streaming</a>, <a href="./Streaming Algorithms – Research_files/Streaming Algorithms – Research.html" rel="tag">Streaming Algorithms</a></span></div></div><div class="post-2089 post type-post status-publish format-standard hentry category-general category-messaging tag-dv-sketch tag-hash-function tag-hashing tag-kmv tag-probabilistic-sketching tag-streaming-algorithms entry"><h2 class="entry-title"><a href="http://research.neustar.biz/2012/08/20/k-minimum-values-sketching-error-hash-functions-and-you/" title="K-Minimum Values: Sketching Error, Hash Functions, and You" rel="bookmark">K-Minimum Values: Sketching Error, Hash Functions, and&nbsp;You</a></h2> 
<div class="post-info"><span class="date published time" title="2012-08-20T07:43:48+00:00">August 20, 2012</span>  by <span class="author vcard"><span class="fn"><a href="http://research.neustar.biz/author/cpesyna/" title="cpesyna" rel="author">cpesyna</a></span></span> <span class="post-comments"><a href="http://research.neustar.biz/2012/08/20/k-minimum-values-sketching-error-hash-functions-and-you/#comments">1 Comment</a></span> </div><div class="entry-content"><h3>Introduction<em><br>
</em></h3>
<p><em>“All known efficient cardinality estimators rely on randomization, which is ensured by the use of hash functions.”<br>
–Flajolet, et al</em></p>
<p>Recalling the KMV algorithm Matt presented in <a title="Sketch of the Day: K-Minimum Values" href="http://blog.aggregateknowledge.com/2012/07/09/sketch-of-the-day-k-minimum-values/">his last post</a>, one will note that every stream element is passed to a hash function as part of the processing step. This is meant to transform the data being operated on from its native distribution into something uniformly distributed. Unfortunately, we don’t live in a perfect world, and since all of the algorithm’s analysis assumes that this hash function does its job well, we wanted to get some sense of how it behaves under less friendly conditions. The first half of this post will investigate the algorithm’s performance when we artificially introduce bias, and the second half will look at its behavior with a handful of real hash functions.</p>
<h3>A Simple Error Model</h3>
<p>The first hash function error model that came to mind is admittedly unrealistic and ham-fisted, but hopefully illustrative. Suppose you have a stream of fixed sized, an ideal hash function, and from these you produce a distinct value estimate using the KMV algorithm. Now suppose that for some unlucky reason, one bit from your hash function is stuck; it’s always a zero or a one, but the other 31 bits are free of this curse.</p>
<p style="text-align:center;"><a href="http://agkn.files.wordpress.com/2012/08/hash_schematic.png"><img class="aligncenter size-full wp-image-2228" title="hash_schematic" src="./Streaming Algorithms – Research_files/hash_schematic.png" alt="Biased hash schematic"></a></p>
<p>There’s nothing to stop you from computing a distinct value estimate using this janky hash with KMV, but your intuition suggests that it shouldn’t be very good. We went through this exact process with various choices of <em>k</em>, using a random number generator to simulate a perfect hash function.</p>
<p>Before we look at the data, let’s think about what we should expect. From the perspective of KMV, it shouldn’t make a whole lot of difference if your&nbsp;<em>k</em>th smallest element is odd or even (for instance, in a case where the lowest order bit always/never set, respectively). It does, however, make a difference if you’re actually incapable of seeing values smaller than 2<sup>31</sup>, which is what happens when the highest order bit is always set. Thus, in both the 0-biasing and 1-biasing cases, we should expect that higher order bits have a much more dramatic effect on error than lower order bits.</p>
<p style="text-align:center;"><a href="http://agkn.files.wordpress.com/2012/08/fixed_bits_kmv.png"><img class="aligncenter  wp-image-2224" title="fixed_bits_KMV" src="./Streaming Algorithms – Research_files/fixed_bits_kmv.png" alt="Error from setting bits in KMV" width="696" height="451"></a></p>
<p>Notice how the performance degradation follows two different patterns. When we are fixing bits as ones, the observed error increases fairly smoothly, and tends to result in under estimates. In contrast, setting bits to zeros results in no change until the error increases producing catastrophic over estimates. Additionally, larger values of <em>k</em> have protective effects against these biases.</p>
<h3>A Somewhat Less Simple Error Model</h3>
<p>Now that we have some intuition for the problem, let’s get a little more subtle. Instead of always setting the <em>n</em>th bit as a 0 or 1, let’s add a probabilistic element. We’ll do the same experiment as before, except we will now fix the <em>n</em>th bit with probability <em>p</em>. Thus, when <em>p </em>= 0 we have a perfectly well behaved KMV, and when <em>p</em> = 1, we have the experiment we just finished discussing. In the following diagram, each tile represents the average error across several experiments in which a stream of 1,000,000 unique elements was fed to a KMV sketch (<em>k </em>= 1024) which was rigged to modify the <em>n</em>th bit with probability <em>p</em>.</p>
<p style="text-align:center;"><a href="http://agkn.files.wordpress.com/2012/08/err_heatmap.png"><img class="aligncenter  wp-image-2215" title="err_heatmap" src="./Streaming Algorithms – Research_files/err_heatmap.png" alt="Heatmap of KMV error" width="696" height="451"></a></p>
<p>Many of the same lessons can be seen here — high order bits matter more, downward biasing degrades performance sharply, upward biasing degrades more smoothly. Additionally, as we’d expect, within a given bit, more bias means more error.</p>
<h3>Send in the Hash Functions</h3>
<p>All of the experiments to this point have involved using a random number generator instead of hashing real data. I think it’s time that we took a look at what happens when we drop in a few real hash functions with real data. For the following experiments, I’m using four 32-bit hashes — <a href="http://code.google.com/p/smhasher/wiki/MurmurHash3" target="_blank">Murmur3</a>, <a href="http://www.cse.yorku.ca/~oz/hash.html" target="_blank">SDBM</a>, <a href="http://www.partow.net/programming/hashfunctions/index.html#APHashFunction" target="_blank">Arash Partow’s hash</a>, and one of the old <a href="http://burtleburtle.net/bob/hash/#lookup" target="_blank">Donald Knuth hashes</a>. You may recall these from our series on <a title="Choosing a Good Hash Function, Part 3" href="http://blog.aggregateknowledge.com/2012/02/02/choosing-a-good-hash-function-part-3/" target="_blank">choosing a good hash function</a> (although 64-bit versions were used there). I chose four text corpuses:</p>
<ul>
<li><em>Romeo and Juliet</em>, stripped of all punctuation and converted to lower case (3794 words)</li>
<li><tt>/usr/share/dict/words</tt> (99171 words)</li>
<li>1,000,000 random 12 character long strings, each sharing the same suffix: “123456”</li>
<li>1,000,000 random 12 character long strings, each sharing the same prefix: “123456”</li>
</ul>
<p>Using formulas from <a href="http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.230.7008" target="_blank">this paper</a>, we can compute the relative error that 99% of KMV estimates should theoretically fall within. This turns out to depend on <em>k</em> and the stream size.</p>
<p>To make these pictures, I chose random values of <em>k</em> within each hash/document pair at which I evaluate the cardinality estimate and compute the relative error. The lines are linear interpolations between sampled points and are shown solely for clarity. The y-axis scale is adjusted on a per-picture basis to best display the theoretical envelope within which we expect our errors to lie.</p>
<p>Now that we’ve gotten through all the necessary preamble, let’s take a look at the results!</p>
<p style="text-align:center;"><a href="http://agkn.files.wordpress.com/2012/08/rj.png"><img class=" wp-image-2173 aligncenter" title="RomeoJulietKMV" src="./Streaming Algorithms – Research_files/rj.png" alt="KMV error for Romeo and Juliet" width="1000" height="636"></a></p>
<p>One picture in and we’ve already learned a lesson: choice of hash function seriously matters! SDBM and DEK cause the algorithm to perform well below its capabilities. DEK’s error is actually off the charts for most of this graph, which is why it does not appear until <em>k</em> &gt; 3,000.</p>
<p><a href="http://agkn.files.wordpress.com/2012/08/words.png"><img class=" wp-image-2177 aligncenter" title="wordsKMV" src="./Streaming Algorithms – Research_files/words.png" alt="KMV error for /usr/bin/dict/words" width="1000" height="636"></a></p>
<p>On a bigger corpus with tighter theoretical error bounds, Murmur3 and AP are still doing quite well. Do note, however, that AP dips outside the envelope for a while at <em>k</em> = 70,000 or so.</p>
<p><img class="alignright  wp-image-2192" title="suffix" src="./Streaming Algorithms – Research_files/suffix.png" alt="KMV error for suffix" width="428" height="273"><a href="http://agkn.files.wordpress.com/2012/08/prefix.png"><img class=" wp-image-2191 aligncenter" title="prefix" src="./Streaming Algorithms – Research_files/prefix.png" alt="KMV error for shared-prefix strings" width="428" height="273"></a></p>
<p>With the random strings, SDBM performs much better than it did on English words. DEK, however, is still hopeless. It’s a little tough to see on these pictures, but at high <em>k</em>, AP starts to fall off the wagon, and even Murmur3 dips outside the envelope, though not beyond what we’d expect, statistically speaking. Honestly, I was hoping for some fireworks here, but they didn’t materialize. I was wondering if we might see some hashes break on one version of these strings, and do fine on the other due to the location of the varying key bits (high order/low order). Sadly, that didn’t happen, but a negative result is a result none the less.</p>
<p>To summarize these, I made the following table, which shows us the percentage of time that an one of the samples falls outside the theoretical envelope. In this view, Murmur3’s superiority is clear.</p>
<table border="0">
<tbody>
<tr>
<th></th>
<th>AP</th>
<th>DEK</th>
<th>Murmur3</th>
<th>SDBM</th>
</tr>
<tr>
<td><em>Romeo and Juliet</em></td>
<td>0.00%</td>
<td>100.00%</td>
<td>0.00%</td>
<td>61.54%</td>
</tr>
<tr>
<td>
<pre data-initialized="true" data-gclp-id="0">/usr/share/dict/words</pre>
</td>
<td>10.76%</td>
<td>100.00%</td>
<td>0.00%</td>
<td>68.46%</td>
</tr>
<tr>
<td>Common Suffix</td>
<td>7.22%</td>
<td>99.11%</td>
<td>1.10%</td>
<td>0.27%</td>
</tr>
<tr>
<td>Common Prefix</td>
<td>3.33%</td>
<td>100.00%</td>
<td>0.22%</td>
<td>0.0001%</td>
</tr>
</tbody>
</table>
<h3>Fin</h3>
<p>KMV is a very nice little algorithm that is incredibly simple to understand, implement, and use. That said, if you’re going to make use of it, you really do need to practice some due diligence when choosing your hash function. With packages like <a href="http://code.google.com/p/smhasher/" target="_blank">smhasher</a> available, trying out multiple hash functions is a cinch, and a little legwork at the start of a project can save you from confusion and despair later on!</p>
</div><div class="post-meta"><span class="categories">Filed Under: <a href="http://research.neustar.biz/category/general/" rel="category tag">General</a>, <a href="http://research.neustar.biz/category/messaging/" rel="category tag">Messaging</a></span> <span class="tags">Tagged With: <a href="http://research.neustar.biz/tag/dv-sketch/" rel="tag">DV Sketch</a>, <a href="http://research.neustar.biz/tag/hash-function/" rel="tag">Hash Function</a>, <a href="http://research.neustar.biz/tag/hashing/" rel="tag">Hashing</a>, <a href="http://research.neustar.biz/tag/kmv/" rel="tag">KMV</a>, <a href="http://research.neustar.biz/tag/probabilistic-sketching/" rel="tag">Probabilistic Sketching</a>, <a href="./Streaming Algorithms – Research_files/Streaming Algorithms – Research.html" rel="tag">Streaming Algorithms</a></span></div></div><div class="post-1503 post type-post status-publish format-standard hentry category-data-science category-general category-programming tag-bloom-filter tag-data-science tag-streaming-algorithms entry"><h2 class="entry-title"><a href="http://research.neustar.biz/2012/01/28/big-data-aint-fat-data-a-case-study/" title="Big Data Ain’t Fat Data: A Case Study" rel="bookmark">Big Data Ain’t Fat Data: A Case&nbsp;Study</a></h2> 
<div class="post-info"><span class="date published time" title="2012-01-28T15:51:00+00:00">January 28, 2012</span>  by <span class="author vcard"><span class="fn"><a href="http://research.neustar.biz/author/blinsay/" title="blinsay" rel="author">blinsay</a></span></span> <span class="post-comments"><a href="http://research.neustar.biz/2012/01/28/big-data-aint-fat-data-a-case-study/#comments">2 Comments</a></span> </div><div class="entry-content"><p>We’ve always had a hunch that our users stick to the same geographic region. Sure, there’s the occasional jet-setter that takes their laptop from New York to Los Angeles (or like Rob, goes Chicago to San Francisco) on a daily or weekly basis, but they’re the exception and not the rule. Knowing how true this is can simplify the way we work with user-centric data across multiple data centers.</p>
<p>When Rob asked me to find this out for sure, my first instinct was to groan and fire up Hive on an Elastic MapReduce cluster, but after a second, I heard Matt’s voice in my head saying, “Big Data isn’t Fat Data”. Why bother with Hadoop?</p>
<h4>The Setup</h4>
<p>If I was solving this problem on a small data-set, it’d be pretty straight-forward. I could write a Python script in about 10 minutes that would take care of the problem. It would probably look something like:</p>
<div><div id="highlighter_294323" class="syntaxhighlighter  python"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div><div class="line number3 index2 alt2">3</div><div class="line number4 index3 alt1">4</div><div class="line number5 index4 alt2">5</div><div class="line number6 index5 alt1">6</div><div class="line number7 index6 alt2">7</div><div class="line number8 index7 alt1">8</div><div class="line number9 index8 alt2">9</div><div class="line number10 index9 alt1">10</div><div class="line number11 index10 alt2">11</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="python plain">users </code><code class="python keyword">=</code> <code class="python plain">{}</code></div><div class="line number2 index1 alt1">&nbsp;</div><div class="line number3 index2 alt2"><code class="python keyword">for</code> <code class="python plain">line </code><code class="python keyword">in</code> <code class="python plain">sys.stdin:</code></div><div class="line number4 index3 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">user, data_center </code><code class="python keyword">=</code> <code class="python plain">parse(line)</code></div><div class="line number5 index4 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python keyword">try</code><code class="python plain">:</code></div><div class="line number6 index5 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">users[user].append(data_center)</code></div><div class="line number7 index6 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python keyword">except</code> <code class="python plain">KeyError:</code></div><div class="line number8 index7 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">users[user] </code><code class="python keyword">=</code> <code class="python plain">[data_center]</code></div><div class="line number9 index8 alt2">&nbsp;</div><div class="line number10 index9 alt1"><code class="python plain">total_users </code><code class="python keyword">=</code> <code class="python functions">len</code><code class="python plain">(users)</code></div><div class="line number11 index10 alt2"><code class="python plain">multiple_dc_users </code><code class="python keyword">=</code> <code class="python functions">len</code><code class="python plain">([u </code><code class="python keyword">for</code> <code class="python plain">u </code><code class="python keyword">in</code> <code class="python plain">users </code><code class="python keyword">if</code> <code class="python functions">len</code><code class="python plain">(users[u]) &gt; </code><code class="python value">1</code><code class="python plain">])</code></div></div></td></tr></tbody></table></div></div>
<p>Easy peasy. However, explicitly storing such a large hash-table gets a little problematic once you start approaching medium-sized data (1GB+). Your memory needs grow pretty rapidly – with M users and N data centers, storage is <em>O(MN)</em> – , and things start to get a little <a href="http://blog.aggregateknowledge.com/2011/11/27/big-memory-part-3-5-google-sparsehash/">slow</a> in Python. At this point there are two options. You can brute force the problem by throwing hardware at it, either with a bigger machine or with something like Hadoop. Or, we can put on our Computer Science and Statistics hats and get a little bit clever.</p>
<p>What if we turn the problem sideways? Above, we’re keeping a hash table that holds a set of data-center for each user. Instead, let’s keep a set of users per data-center, splitting the problem up into multiple hash tables. This lets us keep a small, fixed number of tables – since I’d hope any company knows exactly how many data centers they have – and spread the load across them, hopefully making the load on each table more tolerable. We can then check how many sets each user falls into, and call it a day.</p>
<div><div id="highlighter_170342" class="syntaxhighlighter  python"><table border="0" cellpadding="0" cellspacing="0"><tbody><tr><td class="gutter"><div class="line number1 index0 alt2">1</div><div class="line number2 index1 alt1">2</div><div class="line number3 index2 alt2">3</div><div class="line number4 index3 alt1">4</div><div class="line number5 index4 alt2">5</div><div class="line number6 index5 alt1">6</div><div class="line number7 index6 alt2">7</div><div class="line number8 index7 alt1">8</div><div class="line number9 index8 alt2">9</div><div class="line number10 index9 alt1">10</div><div class="line number11 index10 alt2">11</div><div class="line number12 index11 alt1">12</div></td><td class="code"><div class="container"><div class="line number1 index0 alt2"><code class="python plain">data_centers </code><code class="python keyword">=</code> <code class="python functions">dict</code><code class="python plain">([(dc, </code><code class="python functions">set</code><code class="python plain">()) </code><code class="python keyword">for</code> <code class="python plain">dc </code><code class="python keyword">in</code> <code class="python plain">AK_DATA_CENTERS])</code></div><div class="line number2 index1 alt1">&nbsp;</div><div class="line number3 index2 alt2"><code class="python keyword">for</code> <code class="python plain">line </code><code class="python keyword">in</code> <code class="python plain">sys.stdin:</code></div><div class="line number4 index3 alt1"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">user, data_center </code><code class="python keyword">=</code> <code class="python plain">parse(line)</code></div><div class="line number5 index4 alt2"><code class="python spaces">&nbsp;&nbsp;&nbsp;&nbsp;</code><code class="python plain">data_centers[data_center].add(user)</code></div><div class="line number6 index5 alt1">&nbsp;</div><div class="line number7 index6 alt2"><code class="python comments"># Get the total users by intersecting all of the data center sets</code></div><div class="line number8 index7 alt1"><code class="python plain">...</code></div><div class="line number9 index8 alt2">&nbsp;</div><div class="line number10 index9 alt1"><code class="python comments"># Get all users who are in exactly one set by taking symmetric differences (XOR) of data-center sets</code></div><div class="line number11 index10 alt2"><code class="python comments"># and count the size of that set.</code></div><div class="line number12 index11 alt1"><code class="python plain">...</code></div></div></td></tr></tbody></table></div></div>
<p>While this approach theoretically has better performance with the same <em>O(MN)</em> space requirements, with big enough data the space requirements of the problem totally dominate whatever improvement this approach would provide. In other words, it doesn’t matter how small each hash table is, you can’t fit 80GB of user IDs into the 8GB of RAM on your laptop.</p>
<p>It’s looking pretty bleak for the Clever Way of doing things, since what we really want is a magic hash table that can store our 80GB of user IDs in the memory on our laptops.</p>
<h4>Bloom Filters</h4>
<p>Enter <a title="Bloom Filters" href="http://en.wikipedia.org/wiki/Bloom_filter">Bloom Filters</a>. A bloom filter is a <strong>fixed-size</strong> set data structure with two minor features/drawbacks:</p>
<ol>
<li>You can never ask a Bloom Filter for the set of elements it contains.</li>
<li>Membership queries have a small, controllable, false-positive probability. Bloom filters will never return false negatives.</li>
</ol>
<p>With a little bit of work, it’s pretty easy to substitute Bloom Filters for plain old hash tables in our sideways approach above. There’s a slight tweak we have to make to our algorithm to accommodate the fact that we can’t ever query a bloom filter for the elements it contains, but the idea remains the same.</p>
<h4>The Payoff</h4>
<p>Suppose now we’re keeping a bloom-filter of users per data center. The only thing we have to work around is the fact that we’ll never be able to recover the list of users we’ve added to each set. So, we’ll just deal with users each time we see them instead of deferring our counting to the end.</p>
<p>With that idea in the bag, there are really only a few things to worry about when a request comes in for a given data center.</p>
<ul>
<li>Check the bloom filter for that data center to see if the user has been to that one before</li>
<li>Check the other bloom filters to see how many other data-centers that user has been to before</li>
<li>Count the number of total data-centers that user has seen before. If the user is new to this data center, and the user has seen exactly one other data center before, increment the multiple data center user counter</li>
<li>If the user has never seen any of your data centers before, that user is a completely new user. Increment the total number of users seen.</li>
<li>If the user has already seen this data-center, this user is a repeat. Do nothing!</li>
</ul>
<p>We ran our version of this overnight. It took us one core, 8GB of RAM, and just under than 4 hours to count the number of users who hit multiple data centers in a full week worth of logs.</p>
<p>Not bad!</p>
</div><div class="post-meta"><span class="categories">Filed Under: <a href="http://research.neustar.biz/category/data-science/" rel="category tag">Data Science</a>, <a href="http://research.neustar.biz/category/general/" rel="category tag">General</a>, <a href="http://research.neustar.biz/category/programming/" rel="category tag">Programming</a></span> <span class="tags">Tagged With: <a href="http://research.neustar.biz/tag/bloom-filter/" rel="tag">Bloom Filter</a>, <a href="http://research.neustar.biz/tag/data-science/" rel="tag">Data Science</a>, <a href="./Streaming Algorithms – Research_files/Streaming Algorithms – Research.html" rel="tag">Streaming Algorithms</a></span></div></div><div class="navigation"><div class="pagination-next alignright"><a href="http://research.neustar.biz/tag/streaming-algorithms/page/2/">Next Page»</a></div></div></div></div></div><div id="footer-widgets" class="footer-widgets"><div class="wrap"><div class="footer-widgets-1 widget-area"><div id="text-5" class="widget widget_text"><div class="widget-wrap">			<div class="textwidget"><p style="text-align:center;">© 2014 Neustar. All Rights Reserved.</p></div>
		</div></div>
</div><div class="footer-widgets-2 widget-area"></div><div class="footer-widgets-3 widget-area"></div></div></div><div id="footer" class="footer"><div class="wrap"><div class="gototop"><p><a href="http://research.neustar.biz/tag/streaming-algorithms/#wrap" rel="nofollow">Return to top of page</a></p></div><div class="creds"><p><a href="https://wordpress.com/?ref=footer_blog">Blog at WordPress.com</a>. · <a href="https://wordpress.com/themes/minimum/" title="Learn more about this theme">The Minimum Theme</a>.</p></div></div></div></div>	<div style="display:none">
	</div>

	<div id="bit" class="loggedout-follow-normal" style="bottom: -240px;">
		<a class="bsub" href="javascript:void(0)"><span id="bsub-text">Follow</span></a>
		<div id="bitsubscribe">

					<h3><label for="loggedout-follow-field">Follow “Research”</label></h3>

			<form action="https://subscribe.wordpress.com/" method="post" accept-charset="utf-8" id="loggedout-follow">
			<p>Get every new post delivered to your Inbox.</p>

			<p id="loggedout-follow-error" style="display: none;"></p>

						<p class="bit-follow-count">Join 266 other followers</p>
			<p><input type="email" name="email" value="Enter your email address" onfocus="this.value=(this.value==&quot;Enter your email address&quot;) ? &quot;&quot; : this.value;" onblur="this.value=(this.value==&quot;&quot;) ? &quot;Enter your email address&quot; : this.value;" id="loggedout-follow-field"></p>

			<input type="hidden" name="action" value="subscribe">
			<input type="hidden" name="blog_id" value="22289708">
			<input type="hidden" name="source" value="http://research.neustar.biz/tag/streaming-algorithms/">
			<input type="hidden" name="sub-type" value="loggedout-follow">

			<input type="hidden" id="_wpnonce" name="_wpnonce" value="ec975aa955"><input type="hidden" name="_wp_http_referer" value="/tag/streaming-algorithms/">
			<p id="bsub-subscribe-button"><input type="submit" value="Sign me up"></p>
			</form>
					<div id="bsub-credit"><a href="https://wordpress.com/?ref=lof">Build a website with WordPress.com</a></div>
		</div><!-- #bitsubscribe -->
	</div><!-- #bit -->
<script type="text/javascript" src="./Streaming Algorithms – Research_files/saved_resource(4)"></script>
<script type="text/javascript">
	(function(){
		var corecss = document.createElement('link');
		var themecss = document.createElement('link');
		var corecssurl = "http://s0.wp.com/wp-content/plugins/syntaxhighlighter/syntaxhighlighter3/styles/shCore.css?m=1395343499g&amp;ver=3.0.83c";
		if ( corecss.setAttribute ) {
				corecss.setAttribute( "rel", "stylesheet" );
				corecss.setAttribute( "type", "text/css" );
				corecss.setAttribute( "href", corecssurl );
		} else {
				corecss.rel = "stylesheet";
				corecss.href = corecssurl;
		}
		document.getElementsByTagName("head")[0].insertBefore( corecss, document.getElementById("syntaxhighlighteranchor") );
		var themecssurl = "http://s0.wp.com/wp-content/plugins/syntaxhighlighter/syntaxhighlighter3/styles/shThemeDefault.css?m=1363304414g&amp;ver=3.0.83c";
		if ( themecss.setAttribute ) {
				themecss.setAttribute( "rel", "stylesheet" );
				themecss.setAttribute( "type", "text/css" );
				themecss.setAttribute( "href", themecssurl );
		} else {
				themecss.rel = "stylesheet";
				themecss.href = themecssurl;
		}
		//document.getElementById("syntaxhighlighteranchor").appendChild(themecss);
		document.getElementsByTagName("head")[0].insertBefore( themecss, document.getElementById("syntaxhighlighteranchor") );
	})();
	SyntaxHighlighter.config.strings.expandSource = '+ expand source';
	SyntaxHighlighter.config.strings.help = '?';
	SyntaxHighlighter.config.strings.alert = 'SyntaxHighlighter\n\n';
	SyntaxHighlighter.config.strings.noBrush = 'Can\'t find brush for: ';
	SyntaxHighlighter.config.strings.brushNotHtmlScript = 'Brush wasn\'t configured for html-script option: ';
	SyntaxHighlighter.defaults['pad-line-numbers'] = false;
	SyntaxHighlighter.defaults['toolbar'] = false;
	SyntaxHighlighter.all();
</script>
<script type="text/javascript" src="./Streaming Algorithms – Research_files/devicepx.js"></script>
<script type="text/javascript">
// <![CDATA[
(function() {
try{
  if ( window.external &&'msIsSiteMode' in window.external) {
    if (window.external.msIsSiteMode()) {
      var jl = document.createElement('script');
      jl.type='text/javascript';
      jl.async=true;
      jl.src='/wp-content/plugins/ie-sitemode/custom-jumplist.php';
      var s = document.getElementsByTagName('script')[0];
      s.parentNode.insertBefore(jl, s);
    }
  }
}catch(e){}
})();
// ]]>
</script><script src="./Streaming Algorithms – Research_files/w.js" type="text/javascript"></script>
<script type="text/javascript">
_tkq = window._tkq || [];
_tkq.push(['storeContext', {'blog_id':'22289708','blog_tz':'-8','user_lang':'en','blog_lang':'en','user_id':'0'}]);
st_go({'blog':'22289708','v':'wpcom','tz':'-8','user_id':'0','subd':'agkn'});
ex_go({'crypt':'UE40eW5QN0p8M2Y/RE1LVmwrVi5vQS5fVFtfdHBbPyw1VXIrU3hWLHhmcmw0bWUwNiVnR3N1V2dDZTM4MGFxVndRQl1HNkJtOEQ0dVBbbk9jP2g4T29lWFFNQU9kfHVWQ1VYTllEfk9TS3h+VUIzUjg1c210dFM/MEl0R2dGTj9kMl1vRHB5cD1RWngyY1VscXlQWUdPRlY3P2JYdVNQaF8mdU12Q3B2fFQvdDJHMEg0Um5INGY9W1tVUDNHXTRqVmltZEMsdGpIeXRyX1BKSkR6bWJPTnMrNmdGVD1EM2szYWZ3MWUlJStETHdLNitYZHw0d3pKMlpoWDJdQVtCY2pKcmEzRDFTeSwwa3JdYWVLLXpbQiVPdjFZUG4lLngtRy0wRDYzLzBxZGdWSnY='});
addLoadEvent(function(){linktracker_init('22289708',0);});
	</script><img id="wpstats" src="./Streaming Algorithms – Research_files/g.gif" alt=""><img id="wpstats2" src="./Streaming Algorithms – Research_files/g(1).gif" alt="" style="display:none">
<noscript>&lt;img src="http://pixel.wp.com/b.gif?v=noscript" style="height:0px;width:0px;overflow:hidden" alt="" /&gt;</noscript>
<script>
if ( 'object' === typeof wpcom_mobile_user_agent_info ) {

	wpcom_mobile_user_agent_info.init();
	var mobileStatsQueryString = "";
	
	if( false !== wpcom_mobile_user_agent_info.matchedPlatformName )
		mobileStatsQueryString += "&x_" + 'mobile_platforms' + '=' + wpcom_mobile_user_agent_info.matchedPlatformName;
	
	if( false !== wpcom_mobile_user_agent_info.matchedUserAgentName )
		mobileStatsQueryString += "&x_" + 'mobile_devices' + '=' + wpcom_mobile_user_agent_info.matchedUserAgentName;
	
	if( wpcom_mobile_user_agent_info.isIPad() )
		mobileStatsQueryString += "&x_" + 'ipad_views' + '=' + 'views';

	if( "" != mobileStatsQueryString ) {
		new Image().src = document.location.protocol + '//pixel.wp.com/g.gif?v=wpcom-no-pv' + mobileStatsQueryString + '&baba=' + Math.random();
	}
	
}
</script>
<iframe frameborder="0" scrolling="no" style="border: 0px; display: none; background-color: transparent;"></iframe><div id="GOOGLE_INPUT_CHEXT_FLAG" style="display: none;"></div><div id="html-validator-loading"><img src="chrome-extension://cgndfbhngibokieehnjhbjkkhbfmhojo/images/loading.gif">Validating...</div><div id="html-validator-message"><span id="html-validation-message-close">X</span><div id="html-validator-message-content"></div></div><form id="gclp-frame-form" target="gclp-frame" method="post" style="display: none;"></form><div class="gclp-code-grabber" data-gclp-id="0" data-hasqtip="true" style="left: 476.5px; top: 23168px; display: none;"></div></body></html>